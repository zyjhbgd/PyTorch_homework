{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度强化学习－用卷积神经网络实现AI玩Pie and Bomb游戏\n",
    "\n",
    "《馅饼和炸弹》酝酿自《三体》。三体运动是有规律但不可预测的，三体人将其归纳为恒纪元和乱纪元两种状态是一种简化。在本游戏中，这两种状态是真实存在的，恒纪元天上掉馅饼，乱纪元天上掉炸弹，切换的时间随机没有规律，玩家的任务是收集馅饼，躲开炸弹。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、PyGAME实现Pie and Bomb游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这部分中，我们调用PyGame包实现了一个Flappy Bird游戏。通过PyGame，我们可以非常方便的加载图片、音频，来快速实现小游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载游戏所需的必要资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载游戏中的所有资源，包括图片以及音频\n",
    "# 调用PyGame包，关于该包的安装，请参看：http://www.pygame.org/wiki/GettingStarted\n",
    "import pygame\n",
    "\n",
    "# 需要获取操作系统类型，故而调用sys包\n",
    "import sys\n",
    "def load():\n",
    "    # 加载各类资源的函数\n",
    "    # 精灵在不同状态下的图片\n",
    "    PLAYER_PATH = (\n",
    "            'assets/sprites/redbird-left.png',\n",
    "            'assets/sprites/redbird-right.png',\n",
    "    )\n",
    "\n",
    "    # 背景图地址\n",
    "    BACKGROUND_PATH = 'assets/sprites/background-black.png'\n",
    "\n",
    "    # 馅饼图片所在的地址\n",
    "    PIE_PATH = 'assets/sprites/pie1.png'\n",
    "\n",
    "    # 炸弹图片所在的地址\n",
    "    BOMB_PATH = 'assets/sprites/bomb4.png'\n",
    "\n",
    "    IMAGES, SOUNDS, HITMASKS = {}, {}, {}\n",
    "\n",
    "    # 加载成绩数字所需的图片\n",
    "    IMAGES['numbers'] = (\n",
    "        pygame.image.load('assets/sprites/0.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/1.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/2.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/3.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/4.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/5.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/6.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/7.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/8.png').convert_alpha(),\n",
    "        pygame.image.load('assets/sprites/9.png').convert_alpha()\n",
    "    )\n",
    "\n",
    "    # 加载地面的图片\n",
    "    IMAGES['base'] = pygame.image.load('assets/sprites/base.png').convert_alpha()\n",
    "\n",
    "    # 加载声音文件（在不同的系统中，声音文件扩展名不同）\n",
    "    if 'win' in sys.platform:\n",
    "        soundExt = '.wav'\n",
    "    else:\n",
    "        soundExt = '.ogg'\n",
    "\n",
    "    SOUNDS['die']    = pygame.mixer.Sound('assets/audio/die' + soundExt)\n",
    "    SOUNDS['hit']    = pygame.mixer.Sound('assets/audio/hit' + soundExt)\n",
    "    SOUNDS['point']  = pygame.mixer.Sound('assets/audio/point' + soundExt)\n",
    "    SOUNDS['swoosh'] = pygame.mixer.Sound('assets/audio/swoosh' + soundExt)\n",
    "    SOUNDS['wing']   = pygame.mixer.Sound('assets/audio/wing' + soundExt)\n",
    "\n",
    "    # 加载背景图\n",
    "    IMAGES['background'] = pygame.image.load(BACKGROUND_PATH).convert()\n",
    "\n",
    "    # s加载精灵图\n",
    "    IMAGES['player'] = (\n",
    "        pygame.transform.flip(pygame.image.load(PLAYER_PATH[1]).convert_alpha(), True, False),\n",
    "        pygame.image.load(PLAYER_PATH[1]).convert_alpha(),\n",
    "    )\n",
    "\n",
    "    # 加载馅饼\n",
    "    IMAGES['pie'] = (\n",
    "        pygame.image.load(PIE_PATH).convert_alpha(),\n",
    "    )\n",
    "\n",
    "    # 加载炸弹\n",
    "    IMAGES['bomb'] = (\n",
    "        pygame.image.load(BOMB_PATH).convert_alpha(),\n",
    "    )\n",
    "\n",
    "    # 获得水管的蒙板\n",
    "    HITMASKS['pie'] = (\n",
    "        getHitmask(IMAGES['pie'][0]),\n",
    "    )\n",
    "\n",
    "    # 获得炸弹的蒙板\n",
    "    HITMASKS['bomb'] = (\n",
    "        getHitmask(IMAGES['bomb'][0]),\n",
    "    )\n",
    "\n",
    "    # 玩家的蒙板\n",
    "    HITMASKS['player'] = (\n",
    "        getHitmask(IMAGES['player'][0]),\n",
    "        getHitmask(IMAGES['player'][1]),\n",
    "    )\n",
    "\n",
    "    #返回了三个字典，每个字典的值分别存储图像、声音和蒙板\n",
    "    return IMAGES, SOUNDS, HITMASKS\n",
    "\n",
    "def getHitmask(image):\n",
    "    \"\"\"根据图像的alpha，获得蒙板\"\"\"\n",
    "    #所谓蒙板就是指将图像中的主体从整个图像中抠出来的技术，从而方便与其它的对象合成到一起\n",
    "    #蒙板用一个boolean类型的列表来存储\n",
    "    mask = []\n",
    "    for x in range(image.get_width()):\n",
    "        mask.append([])\n",
    "        for y in range(image.get_height()):\n",
    "            mask[x].append(bool(image.get_at((x,y))[3]))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 实现Flappy Bird的游戏逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载程序所需的包\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import pygame\n",
    "import pygame.surfarray as surfarray\n",
    "from pygame.locals import *\n",
    "from itertools import cycle\n",
    "\n",
    "FPS = 30 #帧率\n",
    "SCREENWIDTH  = 288 #屏幕的宽度\n",
    "SCREENHEIGHT = 512 #屏幕的高度\n",
    "\n",
    "pygame.init() #游戏初始化\n",
    "FPSCLOCK = pygame.time.Clock() #定义程序时钟\n",
    "SCREEN = pygame.display.set_mode((SCREENWIDTH, SCREENHEIGHT)) #定义屏幕对象\n",
    "pygame.display.set_caption('Pie and Bomb') #设定窗口名称\n",
    "\n",
    "IMAGES, SOUNDS, HITMASKS = load() #加载游戏资源\n",
    "#PIPEGAPSIZE = 100 # 定义两个水管之间的宽度\n",
    "BASEY = SCREENHEIGHT * 0.79 #设定基地的高度\n",
    "\n",
    "# 设定小鸟属性：宽度、高度等\n",
    "PLAYER_WIDTH = IMAGES['player'][0].get_width()\n",
    "PLAYER_HEIGHT = IMAGES['player'][0].get_height()\n",
    "\n",
    "# 设定馅饼属性：高度、宽度\n",
    "PIE_WIDTH = IMAGES['pie'][0].get_width()\n",
    "PIE_HEIGHT = IMAGES['pie'][0].get_height()\n",
    "\n",
    "#背景宽度\n",
    "BACKGROUND_WIDTH = IMAGES['background'].get_width()\n",
    "\n",
    "#模式\n",
    "MODE_BOMB = 0\n",
    "MODE_PIE = 1\n",
    "\n",
    "#PLAYER_INDEX_GEN = cycle([0, 1, 2, 1])\n",
    "\n",
    "# 游戏模型类\n",
    "class GameState:\n",
    "    def __init__(self, downVelY, downInterval, pure_prob, modeChangeInterval, showScore):\n",
    "        # 初始化\n",
    "        # 初始成绩、玩家索引、迭代、循环迭代都为0\n",
    "        self.score = self.playerIndex = self.frame = self.loopIter = 0\n",
    "        self.showScore = showScore\n",
    "        self.mode = MODE_BOMB #更快结束\n",
    "        \n",
    "        self.basex = 0\n",
    "        # 地面的初始移位\n",
    "        self.baseShift = IMAGES['base'].get_width() - BACKGROUND_WIDTH\n",
    "\n",
    "        #设定玩家的初始位置\n",
    "        self.playerx = int(SCREENWIDTH * 0.5 - PLAYER_WIDTH * 0.5)\n",
    "        self.playery = int(BASEY-PLAYER_WIDTH)\n",
    "\n",
    "        # 下落物体列表\n",
    "        self.downObjects = []\n",
    "        self.downVelY = downVelY          # 物体下落时y轴上的速度\n",
    "        self.downInterval = downInterval\n",
    "        self.lastDownIter = self.frame\n",
    "        self.pure_prob = pure_prob\n",
    "        \n",
    "        self.modeChangeInterval = modeChangeInterval;\n",
    "        self.lastModeChangeFrame = self.frame\n",
    "\n",
    "        # 定义玩家的属性\n",
    "        self.playerVelX    =  5    # 玩家在x轴上的速度\n",
    "        \n",
    "    def updateDownObject(self):\n",
    "        #更新下降物体\n",
    "        \n",
    "        #模式\n",
    "        if self.frame > 0 and self.frame % self.modeChangeInterval == 0 :\n",
    "            self.mode = 1 - self.mode\n",
    "            self.lastModeChangeFrame = self.frame\n",
    "        \n",
    "        #新物体\n",
    "        if self.frame % self.downInterval == 0 :\n",
    "            #if len(self.downObjects) < self. downCount:\n",
    "                prob = random.uniform(0, 1)\n",
    "                probPie = self.pure_prob if self.mode == MODE_PIE else 1-self.pure_prob\n",
    "                objName = 'pie' if prob < probPie else 'bomb'\n",
    "                self.downObjects.append({'name': objName, 'x':random.randint(0, SCREENWIDTH-PIE_WIDTH), 'y':0})\n",
    "                self.lastDownIter = self.frame\n",
    "        \n",
    "        #下落\n",
    "        for obj in self.downObjects:\n",
    "            obj['y'] += self.downVelY\n",
    "            \n",
    "        #删除旧物体\n",
    "        downObjects = filter(lambda obj:obj['y'] > BASEY,self.downObjects)\n",
    "\n",
    "\n",
    "    def frame_step(self, input_actions):\n",
    "        # input_actions是一个行动数组，分别存储了0或者1两个动作的激活情况\n",
    "        # 游戏每一帧的循环\n",
    "        pygame.event.pump()\n",
    "\n",
    "        # 每一步的默认回报\n",
    "        reward = 0.1\n",
    "        terminal = False\n",
    "\n",
    "        # 限定每一帧只能做一个动作\n",
    "        if sum(input_actions) != 1:\n",
    "            raise ValueError('Multiple input actions!')\n",
    "\n",
    "        # input_actions[0] == 1: 对应什么都不做\n",
    "        # input_actions[1] == 1: 对应左\n",
    "        # input_actions[2] == 1: 对应右\n",
    "        if input_actions[1] == 1:\n",
    "            # 左\n",
    "            self.playerIndex = 0\n",
    "            self.playerx -= self.playerVelX\n",
    "            if self.playerx < 0:\n",
    "                self.playerx = 0\n",
    "                #SOUNDS['wing'].play()\n",
    "        elif input_actions[2] == 1:\n",
    "            # 右\n",
    "            self.playerIndex = 1\n",
    "            self.playerx += self.playerVelX\n",
    "            if self.playerx > SCREENWIDTH - PLAYER_WIDTH:\n",
    "                self.playerx = SCREENWIDTH - PLAYER_WIDTH\n",
    "                #SOUNDS['wing'].play()\n",
    "\n",
    "        # 降落物体的移动\n",
    "        self.updateDownObject()\n",
    "\n",
    "        # 检查碰撞\n",
    "        idxCrash= checkCrash({'x': self.playerx, 'y': self.playery,\n",
    "                             'index': self.playerIndex},\n",
    "                            self.downObjects)\n",
    "        # 如果有碰撞发生，则游戏结束，terminal＝True\n",
    "        if idxCrash>=0:\n",
    "            if self.downObjects[idxCrash]['name'] == 'pie':\n",
    "                self.downObjects.pop(idxCrash)\n",
    "                self.score += 1\n",
    "                #SOUNDS['point'].play()\n",
    "                reward = 1\n",
    "            else :\n",
    "                #SOUNDS['hit'].play()\n",
    "                #SOUNDS['die'].play()\n",
    "                terminal = True\n",
    "                self.__init__(self.downVelY, self.downInterval, self.pure_prob, self.modeChangeInterval, self.showScore)\n",
    "                reward = -1\n",
    "\n",
    "        self.frame += 1\n",
    "        \n",
    "        # 将所有角色都根据每个角色的坐标画到屏幕上\n",
    "        SCREEN.blit(IMAGES['background'], (0,0))\n",
    "\n",
    "        for obj in self.downObjects :\n",
    "            SCREEN.blit(IMAGES[obj['name']][0], (obj['x'], obj['y']))\n",
    "\n",
    "        SCREEN.blit(IMAGES['base'], (self.basex, BASEY))\n",
    "        \n",
    "        if self.showScore :\n",
    "            # print score so player overlaps the score\n",
    "            showScore(self.score)\n",
    "            \n",
    "        SCREEN.blit(IMAGES['player'][self.playerIndex],\n",
    "                    (self.playerx, self.playery))\n",
    "\n",
    "        # 将当前的游戏屏幕生成一个二维画面返回\n",
    "        image_data = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "        pygame.display.update()\n",
    "        FPSCLOCK.tick(FPS)\n",
    "        #print self.upperPipes[0]['y'] + PIPE_HEIGHT - int(BASEY * 0.2)\n",
    "        # 该函数的输出有三个变量：游戏当前帧的游戏画面，当前获得的游戏得分，游戏是否已经结束\n",
    "        return image_data, reward, terminal\n",
    "    \n",
    "\n",
    "def showScore(score):\n",
    "    # 在屏幕上直接展示成绩的函数\n",
    "    \"\"\"displays score in center of screen\"\"\"\n",
    "    scoreDigits = [int(x) for x in list(str(score))]\n",
    "    totalWidth = 0 # total width of all numbers to be printed\n",
    "\n",
    "    for digit in scoreDigits:\n",
    "        totalWidth += IMAGES['numbers'][digit].get_width()\n",
    "\n",
    "    Xoffset = (SCREENWIDTH - totalWidth) / 2\n",
    "\n",
    "    for digit in scoreDigits:\n",
    "        SCREEN.blit(IMAGES['numbers'][digit], (Xoffset, SCREENHEIGHT * 0.1))\n",
    "        Xoffset += IMAGES['numbers'][digit].get_width()\n",
    "\n",
    "\n",
    "def checkCrash(player, downObjects):\n",
    "    # 检测碰撞的函数，基本思路为：将每一个物体都看作是一个矩形区域，然后检查两个矩形区域是否有碰撞\n",
    "    # 检查碰撞是细到每个对象的图像蒙板级别，而不单纯是看矩形之间的碰撞\n",
    "    \"\"\"returns True if player collders with base or pipes.\"\"\"\n",
    "    \n",
    "    #返回值 object的index -1无碰撞\n",
    "    \n",
    "    pi = player['index']\n",
    "    player['w'] = IMAGES['player'][0].get_width()\n",
    "    player['h'] = IMAGES['player'][0].get_height()\n",
    "\n",
    "    # 检查小鸟是否与物体碰撞\n",
    "    playerRect = pygame.Rect(player['x'], player['y'],\n",
    "                  player['w'], player['h'])\n",
    "\n",
    "    #for obj in downObjects :\n",
    "    for i in range(len(downObjects)):\n",
    "        obj = downObjects[i]\n",
    "        # 上下管道矩形\n",
    "        objRect = pygame.Rect(obj['x'], obj['y'], PIE_WIDTH, PIE_HEIGHT)\n",
    "\n",
    "        # 获得每个元素的蒙板\n",
    "        pHitMask = HITMASKS['player'][pi]\n",
    "        oHitmask = HITMASKS['pie'][0]\n",
    "\n",
    "        # 检查是否与上下管道相撞\n",
    "        collide = pixelCollision(playerRect, objRect, pHitMask, oHitmask)\n",
    "\n",
    "        if collide:\n",
    "            return i\n",
    "\n",
    "    return -1\n",
    "\n",
    "def pixelCollision(rect1, rect2, hitmask1, hitmask2):\n",
    "    \"\"\"在像素级别检查两个物体是否发生碰撞\"\"\"\n",
    "    rect = rect1.clip(rect2)\n",
    "\n",
    "    if rect.width == 0 or rect.height == 0:\n",
    "        return False\n",
    "\n",
    "    # 确定矩形框，并针对矩形框中的每个像素进行循环，查看两个对象是否碰撞\n",
    "    x1, y1 = rect.x - rect1.x, rect.y - rect1.y\n",
    "    x2, y2 = rect.x - rect2.x, rect.y - rect2.y\n",
    "\n",
    "    for x in range(rect.width):\n",
    "        for y in range(rect.height):\n",
    "            if hitmask1[x1+x][y1+y] and hitmask2[x2+x][y2+y]:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 对游戏做小测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x44ef2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# 新建一个游戏\n",
    "game = GameState(5, 15, 0.5, 90, True)\n",
    "\n",
    "fig = plt.figure()\n",
    "axe = fig.add_subplot(111)\n",
    "dat = np.zeros((10, 10))\n",
    "img = axe.imshow(dat)\n",
    "\n",
    "# 进行100步循环，并将每一帧的画面打印出来\n",
    "for i in range(100):\n",
    "    clear_output(wait = True)\n",
    "    image_data, reward, terminal = game.frame_step([1,0,0])\n",
    "    \n",
    "    image = np.transpose(image_data, (1, 0, 2))\n",
    "    img.set_data(image)\n",
    "    img.autoscale()\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、训练神经网络玩游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#  导入必需的包\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2 #需要安装OpenCV的包\n",
    "import sys\n",
    "sys.path.append(\"game/\")\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# 定义一系列常数，其中，epsilon为每周期随机输出一个动作的概率\n",
    "GAME = 'pie and bomb' # 游戏名称\n",
    "ACTIONS = 3 # 有效输出动作的个数\n",
    "GAMMA = 0.99 # 强化学习中未来的衰减率\n",
    "OBSERVE = 10000. # 训练之前的时间步，需要先观察10000帧\n",
    "EXPLORE = 3000000. # 退火所需的时间步，所谓的退火就是指随机选择率epsilon逐渐变小\n",
    "FINAL_EPSILON = 0.0001 # epsilon的最终值\n",
    "INITIAL_EPSILON = 0.1 # epsilon的初始值\n",
    "REPLAY_MEMORY = 50000 # 最多记忆多少帧训练数据\n",
    "BATCH = 32 # 每一个批次的数据记录条数\n",
    "FRAME_PER_ACTION = 1 # 每间隔多少时间完成一次有效动作的输出\n",
    "INPUT_IMAGE_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 创建一个多层CNN网络，该网络接收的输入为4帧画面，输出为每个可能动作对应的Q函数值\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 第一层卷积，从4通道到32通道，窗口大小8，跳跃间隔4，填空白2\n",
    "        self.conv1 = nn.Conv2d(4, 32, 8, 4, padding = 2)\n",
    "        # Pooling层，窗口2*2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 第二层卷积，从32通道到64通道，窗口大小4，跳跃间隔2，填空白1\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2, padding = 1)\n",
    "        # 第二个Pooling层，窗口2＊2，空白1\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding = 1)\n",
    "        # 第三层卷积层，输入输出通道都是64，填空白为1\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1, padding = 1)\n",
    "        \n",
    "        # 最后有两层全链接层\n",
    "        self.fc_sz = int( 1600 * (INPUT_IMAGE_SIZE*INPUT_IMAGE_SIZE) /(80*80) )\n",
    "        self.fc1 = nn.Linear(self.fc_sz, 256)\n",
    "        self.fc2 = nn.Linear(256, ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入为一个batch的数据，每一个为前后相连的4张图像，每个图像为80*80的大小\n",
    "        # x的尺寸为：batch_size, 4, 80, 80\n",
    "        x = self.conv1(x)\n",
    "        # x的尺寸为：batch_size, 32, 20, 20\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # x的尺寸为：batch_size, 32, 10, 10\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # x的尺寸为：batch_size, 64, 5, 5\n",
    "        #x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # x的尺寸为：batch_size, 64, 5, 5\n",
    "        #x = self.pool2(x)\n",
    "        # 将x设为1600维的向量, batch_size, 1600\n",
    "        x = x.view(-1, self.fc_sz)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        readout = self.fc2(x)\n",
    "        return readout, x\n",
    "    def init(self):\n",
    "        # 初始化所有的网络权重\n",
    "        self.conv1.weight.data =  torch.abs(0.01 * torch.randn(self.conv1.weight.size()))\n",
    "        self.conv2.weight.data =  torch.abs(0.01 * torch.randn(self.conv2.weight.size()))\n",
    "        self.conv3.weight.data =  torch.abs(0.01 * torch.randn(self.conv3.weight.size()))\n",
    "        self.fc1.weight.data = torch.abs(0.01 * torch.randn(self.fc1.weight.size()))\n",
    "        self.fc2.weight.data = torch.abs(0.01 * torch.randn(self.fc2.weight.size()))\n",
    "        self.conv1.bias.data = torch.ones(self.conv1.bias.size()) * 0.01\n",
    "        self.conv2.bias.data = torch.ones(self.conv2.bias.size()) * 0.01\n",
    "        self.conv3.bias.data = torch.ones(self.conv3.bias.size()) * 0.01\n",
    "        self.fc1.bias.data = torch.ones(self.fc1.bias.size()) * 0.01\n",
    "        self.fc2.bias.data = torch.ones(self.fc2.bias.size()) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 开始在内存／GPU上定义一个网络\n",
    "use_cuda = torch.cuda.is_available() #检测本台机器中是否有GPU\n",
    "\n",
    "# 创建一个神经网络\n",
    "#net = Net()\n",
    "# 初始化网络权重。之所以自定义初始化过程是为了增加神经网络权重的多样性\n",
    "#net.init()\n",
    "\n",
    "#加载\n",
    "net = torch.load('saving_nets_5/pie and bomb-dqn440000.txt')\n",
    "\n",
    "# 如果有GPU，就把神经网络全部搬到GPU内存中做运算\n",
    "net = net.cuda() if use_cuda else net\n",
    "\n",
    "# 定义损失函数为MSE\n",
    "criterion = nn.MSELoss().cuda() if use_cuda else nn.MSELoss()\n",
    "# 定义优化器，并设置初始学习率维10^-6\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-6 )\n",
    "\n",
    "# 开启一个游戏进程，开始与游戏引擎通话\n",
    "game_state = GameState(5, 15, 0.8, 90, False)\n",
    "\n",
    "# 学习样本的存储区域deque是一个类似于list的存储容器\n",
    "D = deque()\n",
    "\n",
    "# 状态打印log记录位置\n",
    "#a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "#h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "# 将游戏设置为初始状态，并获得一个 INPUT_IMAGE_SIZE*INPUT_IMAGE_SIZE 的游戏湖面\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "x_t = cv2.cvtColor(cv2.resize(x_t, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE)), cv2.COLOR_BGR2GRAY)\n",
    "ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# 将初始的游戏画面叠加成4张作为神经网络的初始输入状态s_t\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=0)\n",
    "\n",
    "# 设置初始的epsilon（采取随机行动的概率），并准备训练\n",
    "epsilon = INITIAL_EPSILON\n",
    "epsilon = 0.06\n",
    "t = 0\n",
    "\n",
    "#print(x_t)\n",
    "#print(r_0)\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 边做边学的核心算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该算法分为三个阶段：\n",
    "\n",
    "1、按照Epsilon贪婪算法采取一次行动；\n",
    "2、将选择好的行动输入给游戏引擎，得到下一帧的状态，并生成本帧的训练数据\n",
    "3、开始训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf36\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 1000/（0m 34s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.088877e+01/ 轮得分 nan\n",
      "时间步 2000/（1m 7s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.180499e+01/ 轮得分 nan\n",
      "时间步 3000/（1m 40s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.167113e+01/ 轮得分 nan\n",
      "时间步 4000/（2m 13s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.145040e+01/ 轮得分 nan\n",
      "时间步 5000/（2m 46s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.159599e+01/ 轮得分 nan\n",
      "时间步 6000/（3m 19s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.139811e+01/ 轮得分 nan\n",
      "时间步 7000/（3m 52s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.153592e+01/ 轮得分 351.30\n",
      "时间步 8000/（4m 25s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.120314e+01/ 轮得分 351.30\n",
      "时间步 9000/（4m 58s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.170210e+01/ 轮得分 351.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf36\\lib\\site-packages\\torch\\serialization.py:147: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间步 10000/（5m 31s） 状态 observe/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.120602e+01/ 轮得分 351.30\n",
      "时间步 11000/（6m 58s） 状态 explore/ Loss 0.000000e+00/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.166650e+01/ 轮得分 351.30\n",
      "时间步 12000/（8m 25s） 状态 explore/ Loss 1.194824e-02/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.061639e+01/ 轮得分 351.30\n",
      "时间步 13000/（9m 51s） 状态 explore/ Loss 1.625130e-02/ Epsilon 0.06/ 行动 0/ 奖励 0.1/ Q_MAX 1.165906e+01/ 轮得分 351.30\n",
      "时间步 14000/（11m 18s） 状态 explore/ Loss 9.844925e-03/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.074953e+01/ 轮得分 351.30\n",
      "时间步 15000/（12m 44s） 状态 explore/ Loss 1.075792e-02/ Epsilon 0.06/ 行动 2/ 奖励 0.1/ Q_MAX 1.192516e+01/ 轮得分 493.33\n",
      "时间步 16000/（14m 10s） 状态 explore/ Loss 9.893207e-03/ Epsilon 0.06/ 行动 1/ 奖励 0.1/ Q_MAX 1.157956e+01/ 轮得分 493.33\n"
     ]
    }
   ],
   "source": [
    "# 记录每轮平均得分的容器\n",
    "start = time.time()\n",
    "scores = []\n",
    "all_turn_scores = []\n",
    "loss_rec = 0\n",
    "while \"flappy bird\" != \"angry bird\":\n",
    "    # 开始游戏循环\n",
    "    ######################################################\n",
    "    ##########首先，按照贪婪策略选择一个行动 ##################\n",
    "    s = Variable(torch.from_numpy(s_t).type(torch.FloatTensor))\n",
    "    s = s.cuda() if use_cuda else s\n",
    "    s = s.view(-1, s.size()[0], s.size()[1], s.size()[2])\n",
    "    # 获取当前时刻的游戏画面，输入到神经网络中\n",
    "    readout, h_fc1 = net(s)\n",
    "    # 神经网络产生的输出为readout：选择每一个行动的预期Q值\n",
    "    readout = readout.cpu() if use_cuda else readout\n",
    "    # readout为一个二维向量，分别对应每一个动作的预期Q值\n",
    "    readout_t = readout.data.numpy()[0]\n",
    "\n",
    "    # 按照epsilon贪婪策略产生小鸟的行动，即以epsilon的概率随机输出行动或者以\n",
    "    # 1-epsilon的概率按照预期输出最大的Q值给出行动\n",
    "    a_t = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    if t % FRAME_PER_ACTION == 0:\n",
    "        # 如果当前帧可以行动，则\n",
    "        if random.random() <= epsilon:\n",
    "            # 产生随机行动\n",
    "            #print(\"----------Random Action----------\")\n",
    "            action_index = random.randrange(ACTIONS)\n",
    "        else:\n",
    "            # 选择神经网络判断的预期Q最大的行动\n",
    "            action_index = np.argmax(readout_t)\n",
    "        a_t[action_index] = 1\n",
    "    else:\n",
    "        a_t[0] = 1 # do nothing\n",
    "\n",
    "    # 模拟退火：让epsilon开始降低\n",
    "    if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "        epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "    ######################################################################### \n",
    "    ##########其次，将选择好的行动输入给游戏引擎，并得到下一帧的状态 ################### \n",
    "    x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "    # 返回的x_t1_colored为游戏画面，r_t为本轮的得分，terminal为游戏在本轮是否已经结束\n",
    "    \n",
    "    # 记录一下每一步的成绩\n",
    "    scores.append(r_t)\n",
    "    if terminal:\n",
    "        # 当游戏结束的时候，计算一下本轮的总成绩，并将总成绩存储到all_turn_scores中\n",
    "        all_turn_scores.append(sum(scores))\n",
    "        scores = []\n",
    "    \n",
    "    # 对游戏的原始画面做相应的处理，从而变成一张INPUT_IMAGE_SIZE*INPUT_IMAGE_SIZE的，朴素的（无背景画面）的图\n",
    "    x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "    x_t1 = np.reshape(x_t1, (1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE))\n",
    "    # 将当前帧的画面和前三帧的画面合并起来作为Agent获得的环境反馈结果\n",
    "    s_t1 = np.append(x_t1, s_t[:3, :, :], axis=0)\n",
    "    # 生成一个训练数据，分别将本帧的输入画面s_t,本帧的行动a_t，得到的环境回报r_t以及环境被转换的新状态s_t1存到D中\n",
    "    D.append((s_t, a_t, r_t, s_t1, terminal))\n",
    "    if len(D) > REPLAY_MEMORY:\n",
    "        # 如果D中的元素已满，则扔掉最老的一条训练数据\n",
    "        D.popleft()\n",
    "\n",
    "    ######################################################################### \n",
    "    ##########最后，当运行周期超过一定次数后开始训练神经网络 ################### \n",
    "    if t > OBSERVE:\n",
    "        # 从D中随机采样出一个batch的训练数据\n",
    "        minibatch = random.sample(D, BATCH)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 将这个batch中的s变量都分别存放到列表中\n",
    "        s_j_batch = [d[0] for d in minibatch]\n",
    "        a_batch = [d[1] for d in minibatch]\n",
    "        r_batch = [d[2] for d in minibatch]\n",
    "        s_j1_batch = [d[3] for d in minibatch]\n",
    "\n",
    "        # 接下来，要根据s_j1_batch，神经网络给出预估的未来Q值\n",
    "        \n",
    "        s = Variable(torch.FloatTensor(np.array(s_j1_batch, dtype=float)))\n",
    "        s = s.cuda() if use_cuda else s\n",
    "        readout, h_fc1 = net(s)\n",
    "        readout = readout.cpu() if use_cuda else readout\n",
    "        readout_j1_batch = readout.data.numpy()\n",
    "        # readout_j1_batch存储了一个minibatch中的所有未来一步的Q预估值\n",
    "        # 根据Q的预估值，当前的反馈r，以及游戏是否结束，更新待训练的目标函数值\n",
    "        y_batch = []\n",
    "        for i in range(0, len(minibatch)):\n",
    "            terminal = minibatch[i][4]\n",
    "            # 当游戏结束的时候，则用环境的反馈作为目标，否则用下一状态的Q值＋本期的环境反馈\n",
    "            if terminal:\n",
    "                y_batch.append(r_batch[i])\n",
    "            else:\n",
    "                y_batch.append(r_batch[i] + GAMMA * np.max(readout_j1_batch[i]))\n",
    "\n",
    "        # 开始梯度更新\n",
    "        y = Variable(torch.FloatTensor(y_batch))\n",
    "        a = Variable(torch.FloatTensor(a_batch))\n",
    "        s = Variable(torch.FloatTensor(np.array(s_j_batch, dtype=float)))\n",
    "        if use_cuda:\n",
    "            y = y.cuda()\n",
    "            a = a.cuda()\n",
    "            s = s.cuda()\n",
    "        # 计算s_j_batch的Q值\n",
    "        readout, h_fc1 = net(s)\n",
    "        readout_action = readout.mul(a).sum(1)\n",
    "        # 根据s_j_batch下所选择的预估Q和目标y的Q值的差来作为损失函数训练网络\n",
    "        loss = criterion(readout_action, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % 1000 == 0:\n",
    "            loss_rec = loss.data[0]\n",
    "            #print('损失函数：', loss.data[0])\n",
    "       \n",
    "\n",
    "    # 将状态更新一次，时间步＋1\n",
    "    s_t = s_t1\n",
    "    t += 1\n",
    "\n",
    "    # 每隔 10000 次循环，存储一下网络\n",
    "    if t % 10000 == 0:\n",
    "        torch.save(net, 'saving_nets/' + GAME + '-dqn' + str(t) + '.txt')\n",
    "    \n",
    "    # 状态信息的转化，基本分为Observe，explore和train三个阶段\n",
    "    # Observe没有训练，explore开始训练，并且开始模拟退火，train模拟退火结束\n",
    "    state = \"\"\n",
    "    if t <= OBSERVE:\n",
    "        state = \"observe\"\n",
    "    elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "        state = \"explore\"\n",
    "    else:\n",
    "        state = \"train\"\n",
    "        \n",
    "    # 打印当前运行的一些基本数据，分别输出到屏幕以及log文件中\n",
    "    if t % 1000 == 0:\n",
    "        sss = \"时间步 {}/（{}） 状态 {}/ Loss {:e}/ Epsilon {:.2f}/ 行动 {}/ 奖励 {}/ Q_MAX {:e}/ 轮得分 {:.2f}\".format(\n",
    "            t, time_since(start), state, loss_rec, epsilon, action_index, r_t, np.max(readout_t), np.mean(all_turn_scores[-1000:]))\n",
    "        print(sss)\n",
    "        f = open('log_file.txt', 'a')\n",
    "        f.write(sss + '\\n')\n",
    "        f.close()\n",
    "    # write info to files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqSqbixM9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x37dca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open('final_log_file.txt', 'r')\n",
    "line = f.read().strip().split('\\n')\n",
    "values = []\n",
    "for ln in line:\n",
    "    segs = ln.split('/')\n",
    "    values.append(float(segs[-1].split(' ')[-1]))\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(values))*1000, values)\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Average Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = torch.load('saving_nets/' + GAME + '-dqn' + str(2876000) + '.txt')\n",
    "net = torch.load('final_model.mdl')\n",
    "FINAL_EPSILON = 0.0001 # epsilon的最终值\n",
    "BATCH = 32 # 每一个批次的数据记录条数\n",
    "FRAME_PER_ACTION = 1 # 每间隔多少时间完成一次有效动作的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njIIDCaPgQMIoOJCw/wfNpbMoAP9NdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8a02ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b5ab658cc6ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m# 对游戏的原始画面做相应的处理，从而变成一张INPUT_IMAGE_SIZE*INPUT_IMAGE_SIZE的，朴素的（无背景画面）的图\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mx_t1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t1_colored\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mINPUT_IMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINPUT_IMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_t1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mx_t1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINPUT_IMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINPUT_IMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始在内存／GPU上定义一个网络\n",
    "use_cuda = torch.cuda.is_available() #检测本台机器中是否有GPU\n",
    "\n",
    "# 如果有GPU，就把神经网络全部搬到GPU内存中做运算\n",
    "net = net.cuda() if use_cuda else net\n",
    "\n",
    "# 开启一个游戏进程，开始与游戏引擎通话\n",
    "game_state = GameState(5, 15, 0.8, 90, False)\n",
    "\n",
    "# 状态打印log记录位置\n",
    "#a_file = open(\"logs_\" + GAME + \"/readout.txt\", 'w')\n",
    "#h_file = open(\"logs_\" + GAME + \"/hidden.txt\", 'w')\n",
    "\n",
    "# 将游戏设置为初始状态，并获得一个INPUT_IMAGE_SIZE*INPUT_IMAGE_SIZE的游戏湖面\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "x_t, r_0, terminal = game_state.frame_step(do_nothing)\n",
    "x_t = cv2.cvtColor(cv2.resize(x_t, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE)), cv2.COLOR_BGR2GRAY)\n",
    "ret, x_t = cv2.threshold(x_t,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# 将初始的游戏画面叠加成4张作为神经网络的初始输入状态s_t\n",
    "s_t = np.stack((x_t, x_t, x_t, x_t), axis=0)\n",
    "\n",
    "# 设置初始的epsilon（采取随机行动的概率），并准备训练\n",
    "epsilon = FINAL_EPSILON\n",
    "t = 0# 记录每轮平均得分的容器\n",
    "scores = []\n",
    "all_turn_scores = []\n",
    "\n",
    "fig = plt.figure()\n",
    "axe = fig.add_subplot(111)\n",
    "dat = np.zeros((10, 10))\n",
    "img = axe.imshow(dat)\n",
    "while \"flappy bird\" != \"angry bird\":\n",
    "    # 开始游戏循环\n",
    "    ######################################################\n",
    "    ##########首先，按照贪婪策略选择一个行动 ##################\n",
    "    s = Variable(torch.from_numpy(s_t).type(torch.FloatTensor))\n",
    "    s = s.cuda() if use_cuda else s\n",
    "    s = s.view(-1, s.size()[0], s.size()[1], s.size()[2])\n",
    "    # 获取当前时刻的游戏画面，输入到神经网络中\n",
    "    readout, h_fc1 = net(s)\n",
    "    # 神经网络产生的输出为readout：选择每一个行动的预期Q值\n",
    "    readout = readout.cpu() if use_cuda else readout\n",
    "    # readout为一个二维向量，分别对应每一个动作的预期Q值\n",
    "    readout_t = readout.data.numpy()[0]\n",
    "\n",
    "    # 按照epsilon贪婪策略产生小鸟的行动，即以epsilon的概率随机输出行动或者以\n",
    "    # 1-epsilon的概率按照预期输出最大的Q值给出行动\n",
    "    a_t = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    if t % FRAME_PER_ACTION == 0:\n",
    "        # 如果当前帧可以行动，则\n",
    "        if random.random() <= epsilon:\n",
    "            # 产生随机行动\n",
    "            #print(\"----------Random Action----------\")\n",
    "            action_index = random.randrange(ACTIONS)\n",
    "        else:\n",
    "            # 选择神经网络判断的预期Q最大的行动\n",
    "            action_index = np.argmax(readout_t)\n",
    "        a_t[action_index] = 1\n",
    "    else:\n",
    "        a_t[0] = 1 # do nothing\n",
    "    ######################################################################### \n",
    "    ##########其次，将选择好的行动输入给游戏引擎，并得到下一帧的状态 ################### \n",
    "    x_t1_colored, r_t, terminal = game_state.frame_step(a_t)\n",
    "    # 返回的x_t1_colored为游戏画面，r_t为本轮的得分，terminal为游戏在本轮是否已经结束\n",
    "    \n",
    "    # 记录一下每一步的成绩\n",
    "    scores.append(r_t)\n",
    "    if terminal:\n",
    "        # 当游戏结束的时候，计算一下本轮的总成绩，并将总成绩存储到all_turn_scores中\n",
    "        all_turn_scores.append(sum(scores))\n",
    "        scores = []\n",
    "    \n",
    "    # 对游戏的原始画面做相应的处理，从而变成一张INPUT_IMAGE_SIZE*INPUT_IMAGE_SIZE的，朴素的（无背景画面）的图\n",
    "    x_t1 = cv2.cvtColor(cv2.resize(x_t1_colored, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t1 = cv2.threshold(x_t1, 1, 255, cv2.THRESH_BINARY)\n",
    "    x_t1 = np.reshape(x_t1, (1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE))\n",
    "    # 将当前帧的画面和前三帧的画面合并起来作为Agent获得的环境反馈结果\n",
    "    s_t1 = np.append(x_t1, s_t[:3, :, :], axis=0)\n",
    "    s_t = s_t1\n",
    "    t += 1\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    image = np.transpose(x_t1_colored, (1, 0, 2))\n",
    "    img.set_data(image)\n",
    "    img.autoscale()\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
