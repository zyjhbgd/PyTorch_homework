{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第三节：神经网络莫扎特"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：使用 LSTM 编写一个国际姓氏生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在火炬课程中，我们学习了使用 LSTM 来生成 MIDI 音乐。这节课我们使用类似的方法，再创建一个 LSTM 国际起名大师！\n",
    "\n",
    "完成后的模型能够像下面这样使用，指定一个国家名，模型即生成几个属于这个国家的姓氏。\n",
    "\n",
    "```\n",
    "> python generate.py Russian\n",
    "Rovakov    Uantov    Shavakov\n",
    "\n",
    "> python generate.py German\n",
    "Gerren    Ereng    Rosher\n",
    "\n",
    "> python generate.py Spanish\n",
    "Salla    Parer    Allan\n",
    "\n",
    "> python generate.py Chinese\n",
    "Chan    Hang    Iun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一步当然是引入PyTorch及相关包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这次的数据仍然是18个文本文件，每个文件以“国家名字”命名，文件中存储了大量这个国家的姓氏。\n",
    "\n",
    "在读取这些数据前，为了简化神经网络的输入参数规模，我们把各国各语言人名都转化成用26个英文字母来表示，下面就是转换的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "6a9d80df-1d38-4c41-849c-95e38da98cc7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all_letters 即课支持打印的字符+标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "# Plus EOS marker\n",
    "n_letters = len(all_letters) + 1 \n",
    "EOS = n_letters - 1\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `\"O'Néàl\"` 被转化成了以普通ASCII字符表示的 `O'Neal`。\n",
    "\n",
    "在上面的代码中，还要注意这么几个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
      "n_letters:  59\n",
      "EOS:  58\n"
     ]
    }
   ],
   "source": [
    "# 姓氏中所有的可视字符\n",
    "print('all_letters: ', all_letters)\n",
    "# 所有字符的长度 +1 EOS结束符\n",
    "print('n_letters: ', n_letters)\n",
    "# 结束符，没有实质内容\n",
    "print('EOS: ', EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `all_letters` 包含了我们数据集中所有可能出现的字符，也就是“字符表”。\n",
    "`n_letters` 是字符表的长度，在本例中长度为59。`EOS` 的索引号为58，它在字符表中没有对应的字符，仅代表结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好处理数据的方法，下面就可以放心的读取数据了。\n",
    "\n",
    "我们建立一个列表 `all_categories` 用于存储所有的国家名字。\n",
    "\n",
    "建立一个字典 `category_lines`，以读取的国名作为字典的索引，国名下存储对应国别的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories:  18 ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n",
      "\n",
      "# Russian names:  ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin', 'Abaimoff', 'Abaimov', 'Abakeliya', 'Abakovsky', 'Abakshin']\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "# 按行读取出文件中的名字，并返回包含所有名字的列表\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "\n",
    "# category_lines是一个字典\n",
    "# 其中索引是国家名字，内容是从文件读取出的这个国家的所有名字\n",
    "category_lines = {}\n",
    "# all_categories是一个列表\n",
    "# 其中包含了所有的国家名字\n",
    "all_categories = []\n",
    "# 循环所有文件\n",
    "for filename in glob.glob('./names/*.txt'):\n",
    "    # 从文件名中切割出国家名字\n",
    "    category = os.path.splitext(os.path.split(filename)[-1])[0]\n",
    "    # 将国家名字添加到列表中\n",
    "    all_categories.append(category)\n",
    "    # 读取对应国别文件中所有的名字\n",
    "    lines = read_lines(filename)\n",
    "    # 将所有名字存储在字典中对应的国别下\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 共有的国别数\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories: ', n_categories, all_categories)\n",
    "print()\n",
    "print('# Russian names: ', category_lines['Russian'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "# 再统计下手头共有多少条训练数据\n",
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们的数据准备好了，可以搭建神经网络了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个可以随机选择数据对 `(category, line)` 的方法，以方便训练时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Czech', 'Dolezal')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():\n",
    "    # 随机选择一个国别名\n",
    "    category = random.choice(all_categories)\n",
    "    # 读取这个国别名下的一个人名\n",
    "    line = random.choice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "print(random_training_pair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先处理国别，将国别名转化为索引。\n",
    "\n",
    "这个索引是要和姓氏一起传入神经网络模型的。我们这次编写的是根据“国名条件”生成“符合条件的姓氏”的 LSTM 模型。这种将“条件”和“符合条件的数据”合并一起作为训练输入数据的方法，在“条件模型”里非常流行。\n",
    "\n",
    "比如 条件GAN（Conditional GAN），在训练时是把数据标签拼接到数据图片中一起进行训练的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# 将名字所属的国家名转化为“独热向量”\n",
    "def make_category_input(category):\n",
    "    li = all_categories.index(category)\n",
    "    return  li\n",
    "\n",
    "print(make_category_input('Italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于训练过程中的每一步，或者说对于训练数据中每个名字的每个字符来说，神经网络的输入是 `(category, current letter, hidden state)`，输出是 `(next letter, next hidden state)`。\n",
    "\n",
    "与在课程中讲的一样，神经网络还是依据“当前的字符”预测“下一个字符”。比如对于“Kasparov”这个名字，创建的（input, target）数据对是 (\"K\", \"a\"), (\"a\", \"s\"), (\"s\", \"p\"), (\"p\", \"a\"), (\"a\", \"r\"), (\"r\", \"o\"), (\"o\", \"v\"), (\"v\", \"EOS\")。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cf311809-10bf-40f7-87e1-1952342f7f35"
    }
   },
   "outputs": [],
   "source": [
    "def make_chars_input(nameStr):\n",
    "    name_char_list = list(map(lambda x: all_letters.find(x), nameStr))\n",
    "    return name_char_list\n",
    "\n",
    "\n",
    "def make_target(nameStr):\n",
    "    target_char_list = list(map(lambda x: all_letters.find(x), nameStr[1:]))\n",
    "    target_char_list.append(n_letters - 1)# EOS\n",
    "    return target_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为了训练时方便使用，我们建立一个 `random_training_set` 函数，以随机选择出数据集 `(category, line)` 并转化成训练需要的 Tensor： `(category, input, target) `。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # 随机选择数据集\n",
    "    category, line = random_training_pair()\n",
    "    #print(category, line)\n",
    "    # 转化成对应 Tensor\n",
    "    category_input = make_category_input(category)\n",
    "    line_input = make_chars_input(line)\n",
    "    #category_name_input = make_category_name_input(category, line)\n",
    "    line_target = make_target(line)\n",
    "    return category_input, line_input, line_target\n",
    "    #return category_name_input, line_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, [47, 4, 13, 19, 20, 17, 0], [4, 13, 19, 20, 17, 0, 58])\n"
     ]
    }
   ],
   "source": [
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ff5f52a-2523-47f0-beba-f6c29d412e5f"
    }
   },
   "source": [
    "# 搭建神经网络\n",
    "\n",
    "这次使用的 LSTM 神经网络整体结构上与课上讲的生成音乐的模型非常相似，不过有一点请注意一下。\n",
    "\n",
    "我们要把国别和国别对应的姓氏一同输入到神经网络中，这样 LSTM 模型才能分别学习到每个国家姓氏的特色，从而生成不同国家不同特色的姓氏。\n",
    "\n",
    "那国别数据与姓氏数据应该如何拼接哪？应该在嵌入前拼接，还是在嵌入后再进行拼接哪？嵌入后的维度与 hidden_size 有怎样的关系哪？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要参考课上的模型，将这个模型补充完整。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, category_size, name_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "       \n",
    "        # 进行嵌入\n",
    "        #self.input_size = category_size + name_size\n",
    "        self.embedding_c = nn.Embedding(category_size, hidden_size)\n",
    "        self.embedding_n = nn.Embedding(name_size, hidden_size)\n",
    "        \n",
    "        # 隐含层内部的相互链接\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first = True)\n",
    "        \n",
    "        # 输出层\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, category_variable, name_variable, hidden):\n",
    "        \n",
    "        # 先分别进行embedding层的计算\n",
    "        #print(category_variable)\n",
    "        c = self.embedding_c(category_variable)#1*10\n",
    "        n = self.embedding_n(name_variable)#1*10\n",
    "        #print(c)\n",
    "        #print(n)\n",
    "        \n",
    "        #为什么要加？因为这相当于在嵌入前拼接\n",
    "        embedded = c+n\n",
    "        embedded = embedded.view(1, 1, self.hidden_size)#1*1*10\n",
    "        #print(embedded)\n",
    "        \n",
    "        # 从输入到隐含层的计算\n",
    "        #hhh1 = hidden[0]\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        output = output[:,-1,:]\n",
    "        \n",
    "\n",
    "        # 全连接层\n",
    "        output = self.fc(output)\n",
    "\n",
    "        # output的尺寸：batch_size, output_size\n",
    "        # softmax函数\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前处理得分类问题不同，在分类问题中只有最后的输出被使用。而在当前的 **生成** 姓氏的任务中，神经网络在每一步都会做预测，所以我们需要在每一步计算损失值。\n",
    "\n",
    "PyTorch 非常易用，它允许我们只是简单的把每一步计算的损失加起来，在遍历完一个姓氏后，再进行反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在下面你要定义损失函数、优化函数、实例化模型参数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 20\n",
    "num_epoch = 20\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# 实例化模型\n",
    "#国家数量，字母数量，隐含层节点数，字母数量\n",
    "#国家是个标量，embed之后成为n_categories维向量\n",
    "#同样，字母是个标量，embed之后成为n_letters维向量\n",
    "#隐含层节点数量是超参数可以调节\n",
    "#输出维是字母数量，因为一个字母一类\n",
    "lstm = LSTMNetwork(n_categories, n_letters, HIDDEN_SIZE, n_letters)\n",
    "#lstm = torch.load('homework_lr0.0005_30epoch.mdl')\n",
    "# 定义损失函数与优化方法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要将训练函数补充完整，或者编写自己的训练函数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义训练函数，在这个函数里，我们可以随机选择一条训练数据，遍历每个字符进行训练\n",
    "def train_LSTM():\n",
    "    # 初始化 隐藏层、梯度清零、损失清零\n",
    "    loss = 0\n",
    "    hidden = lstm.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 随机选取一条训练数据\n",
    "    category_input, line_input, line_target = random_training_set()\n",
    "    # 处理国别数据\n",
    "    category_variable = Variable(torch.LongTensor([category_input]))#必须有[]，否则不能正确构造Tensor\n",
    "    #print([category_input, line_input, line_target])\n",
    "    \n",
    "    # 循环字符\n",
    "    for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        x = Variable(torch.LongTensor([line_input[t]]))#必须有[]，否则不能正确构造Tensor\n",
    "        # 目标\n",
    "        y = Variable(torch.LongTensor([line_target[t]]))#必须有[]，否则不能正确构造Tensor\n",
    "        #print(line_input[t])\n",
    "        #print(x)\n",
    "        #print(y)\n",
    "        # 传入模型\n",
    "        #print(hidden)\n",
    "        output, hidden = lstm(category_variable, x, hidden)#别忘了category_variable\n",
    "        # 累加损失\n",
    "        loss += criterion(output, y)\n",
    "    # 计算平均损失\n",
    "    loss = 1.0 * loss / len(line_input)\n",
    "    \n",
    "    # 反向传播、更新梯度\n",
    "    loss.backward(retain_variables = True)\n",
    "    optimizer.step()    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 `time_since` 函数，它可以打印出训练持续的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的过程与我们前几节课一样，都是老套路啦！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "losses = []\n",
    "#抽出的日志函数，方便调用\n",
    "def output_log(epoch, i):\n",
    "    training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "    training_process = '%.2f' % training_process\n",
    "    #loss_stat = train_loss.data.numpy()[0] / i\n",
    "    loss_stat = np.mean(losses)\n",
    "    print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "        .format(epoch, loss_stat, float(training_process), time_since(start)))\n",
    "    records.append([loss_stat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：2.92，训练进度：0.75%，（0m 39s）\n",
      "第0轮，训练损失：2.51，训练进度：1.49%，（1m 17s）\n",
      "第0轮，训练损失：2.38，训练进度：2.24%，（1m 54s）\n",
      "第0轮，训练损失：2.32，训练进度：2.99%，（2m 31s）\n",
      "第0轮，训练损失：2.26，训练进度：3.74%，（3m 8s）\n",
      "第0轮，训练损失：2.22，训练进度：4.48%，（3m 45s）\n",
      "第1轮，训练损失：2.18，训练进度：5.75%，（4m 53s）\n",
      "第1轮，训练损失：2.14，训练进度：6.49%，（5m 31s）\n",
      "第1轮，训练损失：2.14，训练进度：7.24%，（6m 8s）\n",
      "第1轮，训练损失：2.11，训练进度：7.99%，（6m 45s）\n",
      "第1轮，训练损失：2.10，训练进度：8.74%，（7m 23s）\n",
      "第1轮，训练损失：2.06，训练进度：9.48%，（8m 1s）\n",
      "第2轮，训练损失：2.06，训练进度：10.75%，（9m 3s）\n",
      "第2轮，训练损失：2.01，训练进度：11.49%，（9m 40s）\n",
      "第2轮，训练损失：2.03，训练进度：12.24%，（10m 17s）\n",
      "第2轮，训练损失：2.00，训练进度：12.99%，（10m 54s）\n",
      "第2轮，训练损失：2.01，训练进度：13.74%，（11m 31s）\n",
      "第2轮，训练损失：1.99，训练进度：14.48%，（12m 9s）\n",
      "第3轮，训练损失：1.96，训练进度：15.75%，（13m 12s）\n",
      "第3轮，训练损失：1.96，训练进度：16.49%，（13m 48s）\n",
      "第3轮，训练损失：1.96，训练进度：17.24%，（14m 25s）\n",
      "第3轮，训练损失：1.95，训练进度：17.99%，（15m 7s）\n",
      "第3轮，训练损失：1.95，训练进度：18.74%，（15m 44s）\n",
      "第3轮，训练损失：1.94，训练进度：19.48%，（16m 22s）\n",
      "第4轮，训练损失：1.93，训练进度：20.75%，（17m 26s）\n",
      "第4轮，训练损失：1.93，训练进度：21.49%，（18m 4s）\n",
      "第4轮，训练损失：1.93，训练进度：22.24%，（18m 41s）\n",
      "第4轮，训练损失：1.91，训练进度：22.99%，（19m 19s）\n",
      "第4轮，训练损失：1.91，训练进度：23.74%，（19m 57s）\n",
      "第4轮，训练损失：1.90，训练进度：24.48%，（20m 35s）\n",
      "第5轮，训练损失：1.90，训练进度：25.75%，（21m 38s）\n",
      "第5轮，训练损失：1.90，训练进度：26.49%，（22m 14s）\n",
      "第5轮，训练损失：1.89，训练进度：27.24%，（22m 53s）\n",
      "第5轮，训练损失：1.89，训练进度：27.99%，（23m 30s）\n",
      "第5轮，训练损失：1.88，训练进度：28.74%，（24m 9s）\n",
      "第5轮，训练损失：1.87，训练进度：29.48%，（24m 53s）\n",
      "第6轮，训练损失：1.87，训练进度：30.75%，（25m 55s）\n",
      "第6轮，训练损失：1.88，训练进度：31.49%，（26m 32s）\n",
      "第6轮，训练损失：1.88，训练进度：32.24%，（27m 11s）\n",
      "第6轮，训练损失：1.86，训练进度：32.99%，（27m 49s）\n",
      "第6轮，训练损失：1.86，训练进度：33.74%，（28m 26s）\n",
      "第6轮，训练损失：1.84，训练进度：34.48%，（29m 3s）\n",
      "第7轮，训练损失：1.86，训练进度：35.75%，（30m 6s）\n",
      "第7轮，训练损失：1.86，训练进度：36.49%，（30m 44s）\n",
      "第7轮，训练损失：1.86，训练进度：37.24%，（31m 21s）\n",
      "第7轮，训练损失：1.85，训练进度：37.99%，（31m 59s）\n",
      "第7轮，训练损失：1.84，训练进度：38.74%，（32m 36s）\n",
      "第7轮，训练损失：1.82，训练进度：39.48%，（33m 14s）\n",
      "第8轮，训练损失：1.83，训练进度：40.75%，（34m 20s）\n",
      "第8轮，训练损失：1.83，训练进度：41.49%，（35m 3s）\n",
      "第8轮，训练损失：1.83，训练进度：42.24%，（35m 40s）\n",
      "第8轮，训练损失：1.81，训练进度：42.99%，（36m 17s）\n",
      "第8轮，训练损失：1.81，训练进度：43.74%，（36m 55s）\n",
      "第8轮，训练损失：1.83，训练进度：44.48%，（37m 33s）\n",
      "第9轮，训练损失：1.83，训练进度：45.75%，（38m 35s）\n",
      "第9轮，训练损失：1.81，训练进度：46.49%，（39m 12s）\n",
      "第9轮，训练损失：1.80，训练进度：47.24%，（39m 48s）\n",
      "第9轮，训练损失：1.80，训练进度：47.99%，（40m 26s）\n",
      "第9轮，训练损失：1.82，训练进度：48.74%，（41m 5s）\n",
      "第9轮，训练损失：1.82，训练进度：49.48%，（41m 44s）\n",
      "第10轮，训练损失：1.81，训练进度：50.75%，（42m 47s）\n",
      "第10轮，训练损失：1.80，训练进度：51.49%，（43m 24s）\n",
      "第10轮，训练损失：1.80，训练进度：52.24%，（44m 7s）\n",
      "第10轮，训练损失：1.80，训练进度：52.99%，（45m 10s）\n",
      "第10轮，训练损失：1.80，训练进度：53.74%，（45m 48s）\n",
      "第10轮，训练损失：1.80，训练进度：54.48%，（46m 27s）\n",
      "第11轮，训练损失：1.79，训练进度：55.75%，（47m 29s）\n",
      "第11轮，训练损失：1.79，训练进度：56.49%，（48m 7s）\n",
      "第11轮，训练损失：1.79，训练进度：57.24%，（48m 46s）\n",
      "第11轮，训练损失：1.78，训练进度：57.99%，（49m 23s）\n",
      "第11轮，训练损失：1.80，训练进度：58.74%，（50m 0s）\n",
      "第11轮，训练损失：1.79，训练进度：59.48%，（50m 37s）\n",
      "第12轮，训练损失：1.77，训练进度：60.75%，（51m 39s）\n",
      "第12轮，训练损失：1.78，训练进度：61.49%，（52m 16s）\n",
      "第12轮，训练损失：1.79，训练进度：62.24%，（52m 53s）\n",
      "第12轮，训练损失：1.78，训练进度：62.99%，（53m 32s）\n",
      "第12轮，训练损失：1.77，训练进度：63.74%，（54m 12s）\n",
      "第12轮，训练损失：1.80，训练进度：64.48%，（54m 56s）\n",
      "第13轮，训练损失：1.77，训练进度：65.75%，（56m 1s）\n",
      "第13轮，训练损失：1.76，训练进度：66.49%，（56m 38s）\n",
      "第13轮，训练损失：1.78，训练进度：67.24%，（57m 15s）\n",
      "第13轮，训练损失：1.75，训练进度：67.99%，（57m 52s）\n",
      "第13轮，训练损失：1.77，训练进度：68.74%，（58m 30s）\n",
      "第13轮，训练损失：1.76，训练进度：69.48%，（59m 7s）\n",
      "第14轮，训练损失：1.78，训练进度：70.75%，（60m 10s）\n",
      "第14轮，训练损失：1.78，训练进度：71.49%，（60m 47s）\n",
      "第14轮，训练损失：1.79，训练进度：72.24%，（61m 24s）\n",
      "第14轮，训练损失：1.76，训练进度：72.99%，（62m 1s）\n",
      "第14轮，训练损失：1.76，训练进度：73.74%，（62m 38s）\n",
      "第14轮，训练损失：1.77，训练进度：74.48%，（63m 15s）\n",
      "第15轮，训练损失：1.76，训练进度：75.75%，（64m 23s）\n",
      "第15轮，训练损失：1.76，训练进度：76.49%，（65m 7s）\n",
      "第15轮，训练损失：1.76，训练进度：77.24%，（65m 45s）\n",
      "第15轮，训练损失：1.75，训练进度：77.99%，（66m 23s）\n",
      "第15轮，训练损失：1.74，训练进度：78.74%，（67m 2s）\n",
      "第15轮，训练损失：1.71，训练进度：79.48%，（67m 39s）\n",
      "第16轮，训练损失：1.75，训练进度：80.75%，（68m 44s）\n",
      "第16轮，训练损失：1.76，训练进度：81.49%，（69m 22s）\n",
      "第16轮，训练损失：1.74，训练进度：82.24%，（70m 0s）\n",
      "第16轮，训练损失：1.77，训练进度：82.99%，（70m 39s）\n",
      "第16轮，训练损失：1.74，训练进度：83.74%，（71m 17s）\n",
      "第16轮，训练损失：1.73，训练进度：84.48%，（71m 54s）\n",
      "第17轮，训练损失：1.75，训练进度：85.75%，（72m 59s）\n",
      "第17轮，训练损失：1.76，训练进度：86.49%，（73m 38s）\n",
      "第17轮，训练损失：1.75，训练进度：87.24%，（74m 16s）\n",
      "第17轮，训练损失：1.74，训练进度：87.99%，（75m 1s）\n",
      "第17轮，训练损失：1.74，训练进度：88.74%，（75m 40s）\n",
      "第17轮，训练损失：1.76，训练进度：89.48%，（76m 18s）\n",
      "第18轮，训练损失：1.74，训练进度：90.75%，（77m 23s）\n",
      "第18轮，训练损失：1.75，训练进度：91.49%，（78m 1s）\n",
      "第18轮，训练损失：1.73，训练进度：92.24%，（78m 39s）\n",
      "第18轮，训练损失：1.72，训练进度：92.99%，（79m 17s）\n",
      "第18轮，训练损失：1.72，训练进度：93.74%，（79m 55s）\n",
      "第18轮，训练损失：1.74，训练进度：94.48%，（80m 33s）\n",
      "第19轮，训练损失：1.73，训练进度：95.75%，（81m 37s）\n",
      "第19轮，训练损失：1.73，训练进度：96.49%，（82m 15s）\n",
      "第19轮，训练损失：1.72，训练进度：97.24%，（82m 53s）\n",
      "第19轮，训练损失：1.72，训练进度：97.99%，（83m 31s）\n",
      "第19轮，训练损失：1.72，训练进度：98.74%，（84m 9s）\n",
      "第19轮，训练损失：1.75，训练进度：99.48%，（84m 54s）\n",
      "第19轮，训练损失：1.73，训练进度：100.0%，（85m 20s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# 开始训练循环\n",
    "losses = []\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        loss = train_LSTM()\n",
    "        losses.append(loss.data.numpy()[0])\n",
    "        #print(losses)\n",
    "        #print(\"line\")\n",
    "        #break\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 0 and i != 0:#只要去掉i==0时的日志输出，即可避免inf错误\n",
    "            output_log(epoch, i)\n",
    "            losses = []\n",
    "            #break\n",
    "#最后时刻也要输出，以得到最终结果。但如果最后统计的样本数有限又会不准确，自己取舍吧\n",
    "if len(losses)>0:\n",
    "    output_log(num_epoch-1, all_line_num-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\tf36\\lib\\site-packages\\torch\\serialization.py:147: UserWarning: Couldn't retrieve source code for container of type LSTMNetwork. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(lstm,'homework.mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制观察损失曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程中记录的损失绘制成一条曲线，观察下神经网络学习的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xa776ac8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wHLG5nTTkkAygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xace2f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我在计算损失平均值时有“除0错误”，所以在损失曲线中有间断，大家可以改进我的计算方法，让损失曲线连贯起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然神经网络训练好了，那也就是说，我们喂给它第一个字符，他就能生成第二个字符，喂给它第二个字符，它就会生成第三个，这样一直持续下去，直至生成 EOS 才结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那下面我们编写 `generate_one` 函数以方便的使用神经网络生成我们想要的名字字符串，在这个函数里我们定义以下内容：\n",
    "\n",
    "* 建立输入国别，开始字符，初始隐藏层状态的 Tensor\n",
    "* 创建 `output_str` 变量，创建时其中只包含“开始字符”\n",
    "* 定义生成名字的长度最大不超过 `max_length`\n",
    "    * 将当前字符传入神经网络\n",
    "    * 在输出中选出预测的概率最大的下一个字符，同时取出当前的隐藏层状态\n",
    "    * 如果字符是 EOS，则生成结束\n",
    "    * 如果是常规字符，则加入到 `output_str` 中并继续下一个流程\n",
    "* 返回最终生成的名字字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要自行编写模型验证方法。 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 通过指定国别名 category\n",
    "# 以及开始字符 start_char\n",
    "# 还有混乱度 temperature 来生成一个名字\n",
    "def generate_one(category, start_char='A', temperature=0.2):\n",
    "    # 初始化输入数据，国别 以及 输入的第一个字符\n",
    "    # 国别\n",
    "    category_input = make_category_input(category)\n",
    "    category_variable = Variable(torch.LongTensor([category_input]))#必须有[]，否则不能正确构造Tensor\n",
    "    #print([category_input, line_input, line_target])\n",
    "   \n",
    "    # 第一个字符\n",
    "    chars_input = make_chars_input(start_char)\n",
    "    name_variable = Variable(torch.LongTensor([chars_input]))\n",
    "    \n",
    "    # 初始化隐藏层\n",
    "    hidden = lstm.initHidden()\n",
    "\n",
    "    output_str = start_char\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        # 调用模型\n",
    "        output, hidden = lstm(category_variable, name_variable, hidden)#别忘了category_variable\n",
    "        \n",
    "        # 这里是将输出转化为一个多项式分布\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # 生成字符是 EOS，则生成结束\n",
    "        if top_i == EOS:\n",
    "            break\n",
    "        else:\n",
    "            # 继续下一个字符\n",
    "            char = all_letters[top_i]\n",
    "            output_str += char\n",
    "            chars_input = make_chars_input(char)\n",
    "            name_variable = Variable(torch.LongTensor([chars_input]))\n",
    "            \n",
    "    return output_str\n",
    "\n",
    "# 再定义一个函数，方便每次生成多个名字\n",
    "def generate(category, start_chars='ABC', temperature=0.2):\n",
    "    for start_char in start_chars:\n",
    "        print(generate_one(category, start_char, temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rakhin\n",
      "Ukan\n",
      "Shulam\n"
     ]
    }
   ],
   "source": [
    "generate('Russian', 'RUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerder\n",
      "Enggan\n",
      "Rover\n"
     ]
    }
   ],
   "source": [
    "generate('German', 'GER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanganta\n",
      "Pangara\n",
      "Ares\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chan\n",
      "Huo\n",
      "Ing\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asaka\n",
      "Amaga\n",
      "Asaka\n",
      "Vana\n",
      "Vana\n",
      "Vana\n"
     ]
    }
   ],
   "source": [
    "generate('Japanese', 'AAAVVV', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搜索一下这些日本名字，你们懂的，哦吼吼吼~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LSTM 预测的效果，但显然还不理想，我想你可以通过调整网络模型，或者通过调整超参数让模型表现的更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nbpresent": {
   "slides": {
    "10393c05-7962-4245-9228-8b7db4eb79a1": {
     "id": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "prev": "22628fc4-8309-4579-ba36-e5b01a841473",
     "regions": {
      "335fd672-4ee6-4b7c-a65f-3ecbf38305e1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cc294dae-dd8f-4288-8d3c-bb9fd3ad19bc",
        "part": "whole"
       },
       "id": "335fd672-4ee6-4b7c-a65f-3ecbf38305e1"
      }
     }
    },
    "22628fc4-8309-4579-ba36-e5b01a841473": {
     "id": "22628fc4-8309-4579-ba36-e5b01a841473",
     "prev": null,
     "regions": {
      "6cfa5157-02f6-48e3-8ce4-89641febbe59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a73330c-27c1-4957-8e95-c3b42bc14a71",
        "part": "whole"
       },
       "id": "6cfa5157-02f6-48e3-8ce4-89641febbe59"
      }
     }
    },
    "2f34f0df-3ccc-4416-9d5d-cb4b075f539f": {
     "id": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "prev": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "regions": {
      "e25707b9-630e-4ece-9f66-bfcbc8342d76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df50f546-6d02-4383-beab-90378f16576b",
        "part": "whole"
       },
       "id": "e25707b9-630e-4ece-9f66-bfcbc8342d76"
      }
     }
    },
    "3eb7f63f-04de-4f51-a240-38d5074bed6f": {
     "id": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "prev": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "regions": {
      "76282c28-a6ba-4a08-be6c-4f27f5b81ddf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53fb987f-4f42-4bf8-81ae-280ebdd19aee",
        "part": "whole"
       },
       "id": "76282c28-a6ba-4a08-be6c-4f27f5b81ddf"
      }
     }
    },
    "686bcaec-0623-4943-b227-f4e1c5975c4a": {
     "id": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "prev": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "regions": {
      "659c021e-7f79-4612-aa7d-8f1c48f91f8b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ff5f52a-2523-47f0-beba-f6c29d412e5f",
        "part": "whole"
       },
       "id": "659c021e-7f79-4612-aa7d-8f1c48f91f8b"
      }
     }
    },
    "964ac1b6-c781-47e8-89f0-1f593d473cd0": {
     "id": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "prev": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "regions": {
      "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ff6da45-57cd-46ca-b14a-3f560ce4d345",
        "part": "whole"
       },
       "id": "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5"
      }
     }
    },
    "cc4bd43a-59ec-4127-b1d8-ebd30162207a": {
     "id": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "prev": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "regions": {
      "1e6711af-7711-4579-ac7a-f893b0d86931": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cf311809-10bf-40f7-87e1-1952342f7f35",
        "part": "whole"
       },
       "id": "1e6711af-7711-4579-ac7a-f893b0d86931"
      }
     }
    },
    "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8": {
     "id": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "prev": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "regions": {
      "3b983e72-35fb-4d19-83b4-789a3394f61f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597a765d-634b-41a8-a0c6-be5c019da150",
        "part": "whole"
       },
       "id": "3b983e72-35fb-4d19-83b4-789a3394f61f"
      }
     }
    },
    "e4c6fc30-f833-4368-99fe-5297b99f1f14": {
     "id": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "prev": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "regions": {
      "98a6b3b6-d2db-4d8a-bb16-a4307ede4803": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a9d80df-1d38-4c41-849c-95e38da98cc7",
        "part": "whole"
       },
       "id": "98a6b3b6-d2db-4d8a-bb16-a4307ede4803"
      }
     }
    },
    "f1a487d8-4b0b-47df-988f-1161d66174b2": {
     "id": "f1a487d8-4b0b-47df-988f-1161d66174b2",
     "prev": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "regions": {
      "2c817a32-203d-404b-8bf5-ba17f7d27034": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "81fde336-785e-461b-a751-718a5f6bff88",
        "part": "whole"
       },
       "id": "2c817a32-203d-404b-8bf5-ba17f7d27034"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
