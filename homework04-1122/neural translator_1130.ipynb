{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器翻译的神经网络实现\n",
    "\n",
    "本节课我们讲述了利用编码器－解码器架构实现汉－英机器翻译。\n",
    "\n",
    "整个代码包括了数据预处理、编码器＋简单解码器以及编码器＋带有注意力机制的解码器三个部分组成。\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第VIII课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 用到的包\n",
    "#from __future__ import unicode_literals, print_function, division\n",
    "# 进行系统操作，如io、正则表达式的包\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "#import time\n",
    "#import math\n",
    "\n",
    "#Pytorch必备的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as DataSet\n",
    "\n",
    "\n",
    "# 绘图所用的包\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 判断本机是否有支持的GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# 即时绘图\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、数据准备\n",
    "\n",
    "从硬盘读取语料文件，进行基本的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# 读取平行语料库\n",
    "# 这是人民日报语料库\n",
    "lines = open('data/chinese.txt', encoding = 'utf-8')\n",
    "chinese = lines.read().strip().split('\\n')\n",
    "lines = open('data/english.txt', encoding = 'utf-8')\n",
    "english = lines.read().strip().split('\\n')\n",
    "print(len(chinese))\n",
    "print(len(english))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义两个特殊符号，分别对应句子头和句子尾\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "# 定义一个语言类，方便进行自动的建立、词频的统计等\n",
    "# 在这个对象中，最重要的是两个字典：word2index，index2word\n",
    "# 故名思议，第一个字典是将word映射到索引，第二个是将索引映射到word\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        # 在语言中添加一个新句子，句子是用空格隔开的一组单词\n",
    "        # 将单词切分出来，并分别进行处理\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        # 插入一个单词，如果单词已经在字典中，则更新字典中对应单词的频率\n",
    "        # 同时建立反向索引，可以从单词编号找到单词\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "# 将unicode编码转变为ascii编码\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 把输入的英文字符串转成小写\n",
    "def normalizeEngString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "# 对输入的单词对做过滤，保证每句话的单词数不能超过MAX_LENGTH\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# 输入一个句子，输出一个单词对应的编码序列\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "# 和上面的函数功能类似，不同在于输出的序列等长＝MAX_LENGTH\n",
    "def indexFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    for i in range(MAX_LENGTH - len(indexes)):\n",
    "        indexes.append(EOS_token)\n",
    "    return(indexes)\n",
    "\n",
    "# 从一个词对到下标\n",
    "def indexFromPair(pair):\n",
    "    input_variable = indexFromSentence(input_lang, pair[0])\n",
    "    target_variable = indexFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "# 从一个列表到句子\n",
    "def SentenceFromList(lang, lst):\n",
    "    result = [lang.index2word[i] for i in lst if i != EOS_token]\n",
    "    if lang.name == 'Chinese':\n",
    "        result = ' '.join(result)\n",
    "    else:\n",
    "        result = ' '.join(result)\n",
    "    return(result)\n",
    "\n",
    "# 计算准确度的函数\n",
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效句子对： 1836\n",
      "总单词数:\n",
      "Chinese 3324\n",
      "English 3011\n",
      "训练记录： 1653\n",
      "校验记录： 91\n",
      "测试记录： 92\n"
     ]
    }
   ],
   "source": [
    "# 处理数据形成训练数据\n",
    "# 设置句子的最大长度\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "#对英文做标准化处理\n",
    "pairs = [[chi, normalizeEngString(eng)] for chi, eng in zip(chinese, english)]\n",
    "\n",
    "# 对句子对做过滤，处理掉那些超过MAX_LENGTH长度的句子\n",
    "input_lang = Lang('Chinese')\n",
    "output_lang = Lang('English')\n",
    "pairs = [pair for pair in pairs if filterPair(pair)]\n",
    "print('有效句子对：', len(pairs))\n",
    "\n",
    "# 建立两个字典（中文的和英文的）\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(\"总单词数:\")\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "\n",
    "# 形成训练集，首先，打乱所有句子的顺序\n",
    "random_idx = np.random.permutation(range(len(pairs)))\n",
    "pairs = [pairs[i] for i in random_idx]\n",
    "\n",
    "# 将语言转变为单词的编码构成的序列\n",
    "pairs = [indexFromPair(pair) for pair in pairs]\n",
    "    \n",
    "# 形成训练集、校验集和测试集\n",
    "valid_size = len(pairs) // 10\n",
    "if valid_size > 10000:\n",
    "    valid_size = 10000\n",
    "pairs = pairs[ : - valid_size]\n",
    "valid_pairs = pairs[-valid_size : -valid_size // 2]\n",
    "test_pairs = pairs[- valid_size // 2 :]\n",
    "\n",
    "# 利用PyTorch的dataset和dataloader对象，将数据加载到加载器里面，并且自动分批\n",
    "\n",
    "batch_size = 30 #一撮包含30个数据记录，这个数字越大，系统在训练的时候，每一个周期处理的数据就越多，这样处理越快，但总的数据量会减少\n",
    "\n",
    "print('训练记录：', len(pairs))\n",
    "print('校验记录：', len(valid_pairs))\n",
    "print('测试记录：', len(test_pairs))\n",
    "\n",
    "# 形成训练对列表，用于喂给train_dataset\n",
    "pairs_X = [pair[0] for pair in pairs]\n",
    "pairs_Y = [pair[1] for pair in pairs]\n",
    "valid_X = [pair[0] for pair in valid_pairs]\n",
    "valid_Y = [pair[1] for pair in valid_pairs]\n",
    "test_X = [pair[0] for pair in test_pairs]\n",
    "test_Y = [pair[1] for pair in test_pairs]\n",
    "#print(test_Y)\n",
    "\n",
    "\n",
    "# 形成训练集\n",
    "train_dataset = DataSet.TensorDataset(torch.LongTensor(pairs_X), torch.LongTensor(pairs_Y))\n",
    "# 形成数据加载器\n",
    "train_loader = DataSet.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "\n",
    "# 校验数据\n",
    "valid_dataset = DataSet.TensorDataset(torch.LongTensor(valid_X), torch.LongTensor(valid_Y))\n",
    "valid_loader = DataSet.DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "# 测试数据\n",
    "test_dataset = DataSet.TensorDataset(torch.LongTensor(test_X), torch.LongTensor(test_Y))\n",
    "test_loader = DataSet.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、构建编码器及简单的解码器RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建编码器RNN\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # 第一层Embeddeing\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # 第二层GRU，注意GRU中可以定义很多层，主要靠num_layers控制\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True, \n",
    "                          num_layers = self.n_layers, bidirectional = True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #前馈过程\n",
    "        #input尺寸： batch_size, length_seq\n",
    "        embedded = self.embedding(input)\n",
    "        #print(\"embedded\", embedded)\n",
    "        #embedded尺寸：batch_size, length_seq, hidden_size\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output尺寸：batch_size, length_seq, hidden_size\n",
    "        # hidden尺寸：num_layers * directions, batch_size, hidden_size\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 对隐含单元变量全部进行初始化\n",
    "        #num_layers * num_directions, batch, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "# 解码器网络\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # GRU单元\n",
    "        # 设置batch_first为True的作用就是为了让GRU接受的张量可以和其它单元类似，第一个维度为batch_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True,\n",
    "                        num_layers = self.n_layers, bidirectional = True)\n",
    "        # 最后的全链接层\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input大小：batch_size, length_seq\n",
    "        output = self.embedding(input)\n",
    "        # embedded大小：batch_size, length_seq, hidden_size\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output大小：batch_size, length_seq, hidden_size * directions\n",
    "        # hidden大小：n_layers * directions, batch_size, hidden_size\n",
    "        output = self.softmax(self.out(output[:, -1, :]))\n",
    "        # output大小：batch_size * output_size\n",
    "        # 从output中取时间步重新开始\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 初始化隐含单元的状态，输入变量的尺寸：num_layers * directions, batch_size, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进程：0% 训练损失：55.6300，校验损失：46.4623，词正确率：30.77%\n",
      "进程：1% 训练损失：46.6385，校验损失：41.2008，词正确率：31.87%\n",
      "进程：2% 训练损失：43.6524，校验损失：39.9286，词正确率：33.96%\n",
      "进程：3% 训练损失：41.3753，校验损失：41.5583，词正确率：36.26%\n",
      "进程：4% 训练损失：38.6292，校验损失：36.1213，词正确率：37.14%\n",
      "进程：5% 训练损失：36.0598，校验损失：33.2565，词正确率：39.01%\n",
      "进程：6% 训练损失：34.1360，校验损失：33.6611，词正确率：40.22%\n",
      "进程：7% 训练损失：31.7417，校验损失：29.4182，词正确率：41.76%\n",
      "进程：8% 训练损失：30.5023，校验损失：29.0572，词正确率：41.98%\n",
      "进程：9% 训练损失：28.3093，校验损失：26.2841，词正确率：42.53%\n",
      "进程：10% 训练损失：27.0796，校验损失：27.0804，词正确率：43.19%\n",
      "进程：11% 训练损失：25.8310，校验损失：26.5355，词正确率：47.25%\n",
      "进程：12% 训练损失：24.3851，校验损失：19.8535，词正确率：46.26%\n",
      "进程：13% 训练损失：23.6398，校验损失：21.7727，词正确率：48.79%\n",
      "进程：14% 训练损失：22.6077，校验损失：24.5390，词正确率：49.67%\n",
      "进程：15% 训练损失：21.9415，校验损失：22.6638，词正确率：50.77%\n",
      "进程：16% 训练损失：21.2391，校验损失：22.2163，词正确率：52.09%\n",
      "进程：17% 训练损失：19.9517，校验损失：17.0923，词正确率：53.08%\n",
      "进程：18% 训练损失：19.4615，校验损失：17.9907，词正确率：55.27%\n",
      "进程：19% 训练损失：19.3305，校验损失：18.3069，词正确率：56.26%\n",
      "进程：20% 训练损失：18.7687，校验损失：20.5129，词正确率：56.04%\n",
      "进程：21% 训练损失：18.1415，校验损失：18.0479，词正确率：56.04%\n",
      "进程：22% 训练损失：17.0746，校验损失：18.1819，词正确率：56.26%\n",
      "进程：23% 训练损失：17.2795，校验损失：15.6561，词正确率：58.90%\n",
      "进程：24% 训练损失：16.6583，校验损失：13.8527，词正确率：56.26%\n",
      "进程：25% 训练损失：16.2777，校验损失：14.8937，词正确率：55.93%\n",
      "进程：26% 训练损失：15.4257，校验损失：14.0126，词正确率：63.41%\n",
      "进程：27% 训练损失：15.1712，校验损失：18.7723，词正确率：61.21%\n",
      "进程：28% 训练损失：15.2355，校验损失：15.1646，词正确率：63.85%\n",
      "进程：28% 训练损失：14.7489，校验损失：12.3132，词正确率：62.75%\n",
      "进程：30% 训练损失：15.3117，校验损失：16.3215，词正确率：61.54%\n",
      "进程：31% 训练损失：14.3630，校验损失：15.3185，词正确率：61.43%\n",
      "进程：32% 训练损失：14.3795，校验损失：13.6330，词正确率：63.30%\n",
      "进程：33% 训练损失：13.5154，校验损失：11.3917，词正确率：65.27%\n",
      "进程：34% 训练损失：13.5145，校验损失：19.4219，词正确率：66.70%\n",
      "进程：35% 训练损失：13.5393，校验损失：15.0284，词正确率：64.51%\n",
      "进程：36% 训练损失：13.3877，校验损失：12.1278，词正确率：67.03%\n",
      "进程：37% 训练损失：13.1050，校验损失：12.4520，词正确率：67.47%\n",
      "进程：38% 训练损失：12.7893，校验损失：17.4502，词正确率：67.91%\n",
      "进程：39% 训练损失：12.7450，校验损失：13.4335，词正确率：68.35%\n",
      "进程：40% 训练损失：12.0249，校验损失：14.0023，词正确率：66.26%\n",
      "进程：41% 训练损失：11.9431，校验损失：13.7931，词正确率：69.56%\n",
      "进程：42% 训练损失：11.7897，校验损失：15.1850，词正确率：69.89%\n",
      "进程：43% 训练损失：11.3739，校验损失：12.9627，词正确率：70.22%\n",
      "进程：44% 训练损失：11.8026，校验损失：15.9163，词正确率：68.46%\n",
      "进程：45% 训练损失：10.9856，校验损失：12.3926，词正确率：69.56%\n",
      "进程：46% 训练损失：11.8315，校验损失：13.2343，词正确率：72.09%\n",
      "进程：47% 训练损失：11.0918，校验损失：10.4816，词正确率：71.43%\n",
      "进程：48% 训练损失：11.1221，校验损失：15.2556，词正确率：70.11%\n",
      "进程：49% 训练损失：10.7832，校验损失：9.4387，词正确率：72.53%\n",
      "进程：50% 训练损失：11.4987，校验损失：12.1869，词正确率：71.54%\n",
      "进程：51% 训练损失：10.7319，校验损失：8.5342，词正确率：71.87%\n",
      "进程：52% 训练损失：10.7243，校验损失：10.7643，词正确率：70.44%\n",
      "进程：53% 训练损失：10.7946，校验损失：10.0561，词正确率：75.93%\n",
      "进程：54% 训练损失：10.2418，校验损失：16.7434，词正确率：72.42%\n",
      "进程：55% 训练损失：9.6597，校验损失：15.0839，词正确率：74.40%\n",
      "进程：56% 训练损失：9.2969，校验损失：8.7254，词正确率：73.85%\n",
      "进程：56% 训练损失：10.3256，校验损失：9.2021，词正确率：73.30%\n",
      "进程：57% 训练损失：10.2585，校验损失：11.4954，词正确率：73.85%\n",
      "进程：59% 训练损失：10.2207，校验损失：11.7678，词正确率：74.18%\n",
      "进程：60% 训练损失：9.5440，校验损失：10.6702，词正确率：70.88%\n",
      "进程：61% 训练损失：9.4658，校验损失：9.5444，词正确率：74.29%\n",
      "进程：62% 训练损失：10.2587，校验损失：7.9515，词正确率：75.82%\n",
      "进程：63% 训练损失：9.4471，校验损失：10.7335，词正确率：75.93%\n",
      "进程：64% 训练损失：9.0132，校验损失：8.6369，词正确率：74.95%\n",
      "进程：65% 训练损失：8.9391，校验损失：10.3202，词正确率：77.58%\n",
      "进程：66% 训练损失：8.5249，校验损失：8.5719，词正确率：77.80%\n",
      "进程：67% 训练损失：9.2546，校验损失：9.3585，词正确率：76.70%\n",
      "进程：68% 训练损失：9.1089，校验损失：8.1106，词正确率：75.60%\n",
      "进程：69% 训练损失：8.3516，校验损失：7.6178，词正确率：77.47%\n",
      "进程：70% 训练损失：8.7829，校验损失：11.9910，词正确率：74.40%\n",
      "进程：71% 训练损失：8.6764，校验损失：8.7068，词正确率：74.73%\n",
      "进程：72% 训练损失：8.8209，校验损失：10.6735，词正确率：77.91%\n",
      "进程：73% 训练损失：9.0551，校验损失：7.5963，词正确率：77.25%\n",
      "进程：74% 训练损失：8.8138，校验损失：15.5262，词正确率：76.26%\n",
      "进程：75% 训练损失：8.1000，校验损失：10.9548，词正确率：79.78%\n",
      "进程：76% 训练损失：8.1157，校验损失：7.1658，词正确率：78.24%\n",
      "进程：77% 训练损失：8.0311，校验损失：8.6707，词正确率：77.14%\n",
      "进程：78% 训练损失：7.9445，校验损失：7.5167，词正确率：76.59%\n",
      "进程：79% 训练损失：8.2483，校验损失：7.8332，词正确率：75.60%\n",
      "进程：80% 训练损失：8.5975，校验损失：8.0998，词正确率：78.46%\n",
      "进程：81% 训练损失：7.9871，校验损失：9.9830，词正确率：78.24%\n",
      "进程：82% 训练损失：8.3341，校验损失：9.5472，词正确率：76.37%\n",
      "进程：83% 训练损失：7.8553，校验损失：9.6815，词正确率：79.01%\n",
      "进程：84% 训练损失：7.4320，校验损失：8.9670，词正确率：78.57%\n",
      "进程：85% 训练损失：7.4149，校验损失：9.4960，词正确率：78.46%\n",
      "进程：86% 训练损失：8.2202，校验损失：7.7518，词正确率：77.91%\n",
      "进程：87% 训练损失：8.0600，校验损失：9.9434，词正确率：79.45%\n",
      "进程：88% 训练损失：7.3495，校验损失：6.1369，词正确率：82.31%\n",
      "进程：89% 训练损失：6.8608，校验损失：6.4142，词正确率：80.88%\n",
      "进程：90% 训练损失：7.8371，校验损失：6.5808，词正确率：78.02%\n",
      "进程：91% 训练损失：6.8195，校验损失：7.4475，词正确率：81.10%\n",
      "进程：92% 训练损失：7.3020，校验损失：8.6252，词正确率：79.67%\n",
      "进程：93% 训练损失：6.7461，校验损失：5.7979，词正确率：82.31%\n",
      "进程：94% 训练损失：6.8640，校验损失：6.7840，词正确率：80.99%\n",
      "进程：95% 训练损失：6.8038，校验损失：6.3652，词正确率：81.32%\n",
      "进程：96% 训练损失：6.9946，校验损失：8.6908，词正确率：80.55%\n",
      "进程：97% 训练损失：7.3830，校验损失：12.5781，词正确率：81.10%\n",
      "进程：98% 训练损失：6.8738，校验损失：12.2731，词正确率：79.78%\n",
      "进程：99% 训练损失：6.7539，校验损失：9.6339，词正确率：81.43%\n"
     ]
    }
   ],
   "source": [
    "# 开始训练过程\n",
    "# 定义网络结构\n",
    "hidden_size = 16\n",
    "max_length = MAX_LENGTH\n",
    "n_layers = 1\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers = n_layers)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words, n_layers = n_layers)\n",
    "\n",
    "if use_cuda:\n",
    "    # 如果本机有GPU可用，则将模型加载到GPU上\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "learning_rate = 0.01\n",
    "# 为两个网络分别定义优化器\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.NLLLoss()\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "plot_losses = []\n",
    "\n",
    "# 开始200轮的循环\n",
    "num_epoch = 100\n",
    "for epoch in range(num_epoch):\n",
    "    print_loss_total = 0\n",
    "    # 对训练数据循环\n",
    "    for data in train_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        #print(\"input_variable\", input_variable)\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "        \n",
    "        # 初始化编码器状态\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "        # 清空梯度\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # 开始编码器的计算，对时间步的循环由系统自动完成\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        #print(\"encoder_outputs\", encoder_outputs)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "        \n",
    "        # 开始解码器的工作\n",
    "        # 输入给解码器的第一个字符\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        #print(\"decoder_input\",decoder_input)\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        # 让解码器的隐藏层状态等于编码器的隐藏层状态\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 以teacher_forcing_ratio的比例用target中的翻译结果作为监督信息\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        base = torch.zeros(target_variable.size()[0])\n",
    "        if use_teacher_forcing:\n",
    "            # 教师监督: 将下一个时间步的监督信息输入给解码器\n",
    "            # 对时间步循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 开始一步解码\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                # decoder_ouput大小：batch_size, output_size\n",
    "                # 计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "                #print(\"decoder_output\",decoder_output)\n",
    "                #print(\"target_variable[:, di]\", target_variable[:, di])\n",
    "                # 将训练数据当做下一时间步的输入\n",
    "                decoder_input = target_variable[:, di].unsqueeze(1)  # Teacher forcing\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                #print(\"decoder_input\", decoder_input)\n",
    "                \n",
    "        else:\n",
    "            # 没有教师训练: 使用解码器自己的预测作为下一时间步的输入\n",
    "            # 开始对时间步进行循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 进行一步解码\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "                \n",
    "                #从输出结果（概率的对数值）中选择出一个数值最大的单词作为输出放到了topi中\n",
    "                topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "                #topi 尺寸：batch_size, k\n",
    "                ni = topi[:, 0]\n",
    "\n",
    "                # 将输出结果ni包裹成Variable作为解码器的输入\n",
    "                decoder_input = Variable(ni.unsqueeze(1))\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                #计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "        \n",
    "            \n",
    "        \n",
    "        # 开始反向传播\n",
    "        loss.backward()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 开始梯度下降\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        # 累加总误差\n",
    "        print_loss_total += loss.data.numpy()[0]\n",
    "\n",
    "    # 计算训练时候的平均误差\n",
    "    print_loss_avg = print_loss_total / len(train_loader)\n",
    "        \n",
    "    # 开始跑校验数据集\n",
    "    valid_loss = 0\n",
    "    rights = []\n",
    "    # 对校验数据集循环\n",
    "    for data in valid_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 没有教师监督: 使用解码器自己的预测作为下一时间步解码器的输入\n",
    "        for di in range(MAX_LENGTH):\n",
    "            # 一步解码器运算\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "            \n",
    "            # 选择输出最大的项作为解码器的预测答案\n",
    "            topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "            #topi 尺寸：batch_size, k\n",
    "            ni = topi[:, 0]\n",
    "            decoder_input = Variable(ni.unsqueeze(1))\n",
    "            # decoder_input大小：batch_size, length_seq\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            \n",
    "            # 计算预测的准确率，记录在right中，right为一个二元组，分别存储猜对的个数和总数\n",
    "            right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "            rights.append(right)\n",
    "            \n",
    "            # 计算损失函数\n",
    "            loss += criterion(decoder_output, target_variable[:, di])\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 累加校验时期的损失函数\n",
    "        valid_loss += loss.data.numpy()[0]\n",
    "    # 打印每一个Epoch的输出结果\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('进程：%d%% 训练损失：%.4f，校验损失：%.4f，词正确率：%.2f%%' % (epoch * 1.0 / num_epoch * 100, \n",
    "                                                    print_loss_avg,\n",
    "                                                    valid_loss / len(valid_loader),\n",
    "                                                    100.0 * right_ratio))\n",
    "    # 记录基本统计指标\n",
    "    plot_losses.append([print_loss_avg, valid_loss / len(valid_loader), right_ratio])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x47a92dd8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVgQajUZj52hFoNFoNHbO/wPZ4kxpHEwZOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f876c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将统计指标绘图\n",
    "a = [i[0] for i in plot_losses]\n",
    "b = [i[1] for i in plot_losses]\n",
    "c = [i[2] * 100 for i in plot_losses]\n",
    "plt.plot(a, label = 'Training Loss')\n",
    "plt.plot(b, label = 'Validation Loss')\n",
    "plt.plot(c, label = 'Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "但是 这种 情况 近日 已 得到 改变 .\n",
      "机器翻译： it inalienable heading sailed heading\n",
      "标准翻译： such a situation has changed lately however .\n",
      "词准确率： 60.0\n",
      "\n",
      "\n",
      "我们 支持 海外侨胞 反 \" 独 \" 促 统 的 正义 行动 .\n",
      "机器翻译： village village is providing is thinking embody raise\n",
      "标准翻译： we support the just activities of overseas chinese abroad in opposing independence and promoting reunification .\n",
      "词准确率： 20.0\n",
      "\n",
      "\n",
      "最近 双方 在 杜尚别 会晤 时 , 讨论 了 一些 亟待 解决 的 问题 .\n",
      "机器翻译： is transmitted strategy strategy transmitted strategy armey topic server\n",
      "标准翻译： both sides met recently in dushanbe where they discussed some issues requiring urgent solution .\n",
      "词准确率： 25.0\n",
      "\n",
      "\n",
      "总之 , 模糊 是 它的 本质 .\n",
      "机器翻译： began began alarm began began a press server\n",
      "标准翻译： in a word ambiguity is the essence of the speech .\n",
      "词准确率： 45.0\n",
      "\n",
      "\n",
      "详细 情况 仍在 调查 中 .\n",
      "机器翻译： pursue pursue with with long two pursue server\n",
      "标准翻译： the details of this accident are still under investigation .\n",
      "词准确率： 50.0\n",
      "\n",
      "\n",
      "这 当然 是 绝对 不能 允许 的 , 而且 已经 遭到 祖国 大陆 的 坚决 反对 .\n",
      "机器翻译： village strategy is strategy abundant a management management scientific server\n",
      "标准翻译： this of course absolutely cannot be permitted and has been met with resolute opposition from the mainland .\n",
      "词准确率： 10.0\n",
      "\n",
      "\n",
      "科索沃 战争 结束 后 , 阿族 强硬派 势力 迅速 膨胀 .\n",
      "机器翻译： is utilization million is slacken final analysis shipping something server\n",
      "标准翻译： after the ending of the war in kosovo the strength of albanian hard liners quickly expanded .\n",
      "词准确率： 15.0\n",
      "\n",
      "\n",
      "这是 改革开放 的 必然 结果 .\n",
      "机器翻译： region issue young young providing china raise\n",
      "标准翻译： this is the necessary result of reform and opening up .\n",
      "词准确率： 45.0\n",
      "\n",
      "\n",
      "武警 8710 队 官兵 收看 了 新闻 后 , 心情 十分 激动 .\n",
      "机器翻译： pursue annals pursue annals issue pursue annals raise\n",
      "标准翻译： after watching the news report officers and men of no . armed police unit were very excited .\n",
      "词准确率： 10.0\n",
      "\n",
      "\n",
      "克林顿 的话 并不 夸张 .\n",
      "机器翻译： long awareness threatens awareness be and and server\n",
      "标准翻译： clinton s remarks were not exaggerated .\n",
      "词准确率： 60.0\n",
      "\n",
      "\n",
      "\" 我们 经历 的 这类 事件 并 不能 增进 两国 间 的 建设性 关系 . \"\n",
      "机器翻译： is necessary million is necessary and and breakthroughs server\n",
      "标准翻译： and the kind of incident we have experienced really cannot further constructive relations between the two countries . \n",
      "词准确率： 5.0\n",
      "\n",
      "\n",
      "当年 签订 \" 十七 协议 \" 时 , 也 不是 一帆风顺 的 .\n",
      "机器翻译： debt village is is a expand diligently\n",
      "标准翻译： it was not plain sailing either when the point agreement was signed at that time .\n",
      "词准确率： 20.0\n",
      "\n",
      "\n",
      "二 是 注重 拓展 服务 保证 的 新 领域 .\n",
      "机器翻译： among substantial threatens threatens a substantial server\n",
      "标准翻译： second we must focus on expanding the new territory in service guarantees .\n",
      "词准确率： 35.0\n",
      "\n",
      "\n",
      "这些 国际间 的 合作 和 交流 有力地 促进 了 中国 国内 反腐败 斗争 工作 .\n",
      "机器翻译： msar a a a a a moreover\n",
      "标准翻译： such international cooperation and exchange has effectively promoted china s efforts in fighting against corruption at home .\n",
      "词准确率： 10.0\n",
      "\n",
      "\n",
      "今天 , 海军 一线 舰长 全都 毕业 於 专业 院校 .\n",
      "机器翻译： consciousness about strategy alarm is terms server it\n",
      "标准翻译： today all the frontline captains of the navy are graduates from specialist academies and institutions .\n",
      "词准确率： 20.0\n",
      "\n",
      "\n",
      "大多数 地区 经济效益 明显 提高 .\n",
      "机器翻译： region lam be  tsuen lavish naturally\n",
      "标准翻译： the economic efficiency in the majority of regions has improved significantly .\n",
      "词准确率： 40.0\n",
      "\n",
      "\n",
      "来自 加拿大 的 学者 就 美国 反 邪教 活动 进行 了 评介 .\n",
      "机器翻译： is punitive brought conducive is punitive interest armey server it\n",
      "标准翻译： a scholar from canada made come comments on the activities of opposing evil cults in the united states .\n",
      "词准确率： 5.0\n",
      "\n",
      "\n",
      "六 , 不断 改进 为 委员 履行 职能 服务 的 各项 工作 .\n",
      "机器翻译： village strategy is strategy liu liu pursue server\n",
      "标准翻译：  continually improving work in various areas in service of the members performance of functions .\n",
      "词准确率： 20.0\n",
      "\n",
      "\n",
      "他 说 , 这是 在 世纪之交 的 一次 重要 访问 .\n",
      "机器翻译： publicity an facilities is is a formed formed server\n",
      "标准翻译： he said the visit was an important one at the turn of the century .\n",
      "词准确率： 25.0\n",
      "\n",
      "\n",
      "中国 不需要 其他 国家 在 台湾 问题 上 参与 或 干预 .\n",
      "机器翻译： comparatively strategy comparatively a opposed endangers server\n",
      "标准翻译： china does not need any other countries to participate in or interfere in the taiwan issue .\n",
      "词准确率： 15.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上测试模型运行的效果\n",
    "\n",
    "# 首先，在测试集中随机选择20个句子作为测试\n",
    "indices = np.random.choice(range(len(test_X)), 20)\n",
    "\n",
    "# 对每个句子进行循环\n",
    "for ind in indices:\n",
    "    data = [test_X[ind]]\n",
    "    target = [test_Y[ind]]\n",
    "    # 把源语言的句子打印出来\n",
    "    print(SentenceFromList(input_lang, data[0]))\n",
    "    input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "    # input_variable的大小：batch_size, length_seq\n",
    "    target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "    # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "    # 初始化编码器\n",
    "    encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # 编码器开始编码，结果存储到了encoder_hidden中\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "    # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # 将SOS作为解码器的第一个输入\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    # 将编码器的隐含层单元数值拷贝给解码器的隐含层单元\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # 没有教师指导下的预测: 使用解码器自己的预测作为解码器下一时刻的输入\n",
    "    output_sentence = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    rights = []\n",
    "    # 按照输出字符进行时间步循环\n",
    "    for di in range(MAX_LENGTH):\n",
    "        # 解码器一个时间步的计算\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "        \n",
    "        # 解码器的输出\n",
    "        topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "        #topi 尺寸：batch_size, k\n",
    "        ni = topi[:, 0]\n",
    "        decoder_input = Variable(ni.unsqueeze(1))\n",
    "        #print(ni)\n",
    "        ni = ni[0]\n",
    "        \n",
    "        # 将本时间步输出的单词编码加到output_sentence里面\n",
    "        output_sentence.append(ni)\n",
    "        #print(output_sentence)\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        \n",
    "        # 计算输出字符的准确度\n",
    "        right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "        rights.append(right)\n",
    "    # 解析出编码器给出的翻译结果\n",
    "    sentence = SentenceFromList(output_lang, output_sentence)\n",
    "    # 解析出标准答案\n",
    "    standard = SentenceFromList(output_lang, target[0])\n",
    "    \n",
    "    # 将句子打印出来\n",
    "    print('机器翻译：', sentence)\n",
    "    print('标准翻译：', standard)\n",
    "    # 输出本句话的准确率\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('词准确率：', 100.0 * right_ratio)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效句子对： 19919\n",
      "总单词数:\n",
      "English 13493\n",
      "Chinese 18671\n",
      "训练记录： 17928\n",
      "校验记录： 995\n",
      "测试记录： 996\n"
     ]
    }
   ],
   "source": [
    "# 重新处理数据形成训练数据、校验数据与测试数据，主要是MAX_Length更大了\n",
    "# 设置句子的最大长度\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "#对英文做标准化处理\n",
    "pairs = [[normalizeEngString(eng), chi] for chi, eng in zip(chinese, english)]\n",
    "\n",
    "# 对句子对做过滤，处理掉那些超过MAX_LENGTH长度的句子\n",
    "input_lang = Lang('English')\n",
    "output_lang = Lang('Chinese')\n",
    "pairs = [pair for pair in pairs if filterPair(pair)]\n",
    "print('有效句子对：', len(pairs))\n",
    "\n",
    "# 建立两个字典（中文的和英文的）\n",
    "for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "print(\"总单词数:\")\n",
    "print(input_lang.name, input_lang.n_words)\n",
    "print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "\n",
    "# 形成训练集，首先，打乱所有句子的顺序\n",
    "random_idx = np.random.permutation(range(len(pairs)))\n",
    "pairs = [pairs[i] for i in random_idx]\n",
    "\n",
    "# 将语言转变为单词的编码构成的序列\n",
    "pairs = [indexFromPair(pair) for pair in pairs]\n",
    "    \n",
    "# 形成训练集、校验集和测试集\n",
    "valid_size = len(pairs) // 10\n",
    "if valid_size > 10000:\n",
    "    valid_size = 10000\n",
    "pairs = pairs[ : - valid_size]\n",
    "valid_pairs = pairs[-valid_size : -valid_size // 2]\n",
    "test_pairs = pairs[- valid_size // 2 :]\n",
    "\n",
    "# 利用PyTorch的dataset和dataloader对象，将数据加载到加载器里面，并且自动分批\n",
    "\n",
    "batch_size = 30 #一撮包含30个数据记录，这个数字越大，系统在训练的时候，每一个周期处理的数据就越多，这样处理越快，但总的数据量会减少\n",
    "\n",
    "print('训练记录：', len(pairs))\n",
    "print('校验记录：', len(valid_pairs))\n",
    "print('测试记录：', len(test_pairs))\n",
    "\n",
    "# 形成训练对列表，用于喂给train_dataset\n",
    "pairs_X = [pair[0] for pair in pairs]\n",
    "pairs_Y = [pair[1] for pair in pairs]\n",
    "valid_X = [pair[0] for pair in valid_pairs]\n",
    "valid_Y = [pair[1] for pair in valid_pairs]\n",
    "test_X = [pair[0] for pair in test_pairs]\n",
    "test_Y = [pair[1] for pair in test_pairs]\n",
    "\n",
    "\n",
    "# 形成训练集\n",
    "train_dataset = DataSet.TensorDataset(torch.LongTensor(pairs_X), torch.LongTensor(pairs_Y))\n",
    "# 形成数据加载器\n",
    "train_loader = DataSet.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "\n",
    "# 校验数据\n",
    "valid_dataset = DataSet.TensorDataset(torch.LongTensor(valid_X), torch.LongTensor(valid_Y))\n",
    "valid_loader = DataSet.DataLoader(valid_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "# 测试数据\n",
    "test_dataset = DataSet.TensorDataset(torch.LongTensor(test_X), torch.LongTensor(test_Y))\n",
    "test_loader = DataSet.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, num_workers = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义基于注意力的解码器RNN\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        # 注意力网络（一个前馈神经网络）\n",
    "        self.attn = nn.Linear(self.hidden_size * (2 * n_layers + 1), self.max_length)\n",
    "    \n",
    "        # 注意力机制作用完后的结果映射到后面的层\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 3, self.hidden_size)\n",
    "        \n",
    "        # dropout操作层\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # 定义一个双向GRU，并设置batch_first为True以方便操作\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, bidirectional = True,\n",
    "                         num_layers = self.n_layers, batch_first = True)\n",
    "        self.out = nn.Linear(self.hidden_size * 2, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # 解码器的一步操作\n",
    "        # input大小：batch_size, length_seq\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded大小：batch_size, length_seq, hidden_size\n",
    "        embedded = embedded[:, 0, :]\n",
    "        # embedded大小：batch_size, hidden_size\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # 将hidden张量数据转化成batch_size排在第0维的形状\n",
    "        # hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "        temp_for_transpose = torch.transpose(hidden, 0, 1).contiguous()\n",
    "        # hidden大小：batch_size, direction*n_layer, hidden_size\n",
    "        temp_for_transpose = temp_for_transpose.view(temp_for_transpose.size()[0], -1)\n",
    "        # hidden大小：batch_size, direction*n_layer*hidden_size\n",
    "        hidden_attn = temp_for_transpose\n",
    "        \n",
    "        # 注意力层的输入\n",
    "        # hidden_attn大小：batch_size, direction*n_layers*hidden_size\n",
    "        input_to_attention = torch.cat((embedded, hidden_attn), 1)\n",
    "        # input_to_attention大小：batch_size, hidden_size * (1 + direction * n_layers)\n",
    "        \n",
    "        # 注意力层输出的权重\n",
    "        attn_weights = F.softmax(self.attn(input_to_attention))\n",
    "        # attn_weights大小：batch_size, max_length\n",
    "        \n",
    "        # 当输入数据不标准的时候，对weights截取必要的一段\n",
    "        attn_weights = attn_weights[:, : encoder_outputs.size()[1]]\n",
    "        # attn_weights大小：batch_size, length_seq_of_encoder\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        # attn_weights大小：batch_size, 1, length_seq 中间的1是为了bmm乘法用的\n",
    "        \n",
    "        # 将attention的weights矩阵乘encoder_outputs以计算注意力完的结果\n",
    "        # encoder_outputs大小：batch_size, seq_length, hidden_size*direction\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs) \n",
    "        # attn_applied大小：batch_size, 1, hidden_size*direction\n",
    "        # bmm: 两个矩阵相乘。忽略第一个batch纬度，缩并时间维度\n",
    "        # batch matrix multiply ?\n",
    "        \n",
    "        # 将输入的词向量与注意力机制作用后的结果拼接成一个大的输入向量\n",
    "        output = torch.cat((embedded, attn_applied[:,0,:]), 1)\n",
    "        # output大小：batch_size, hidden_size * (direction + 1)\n",
    "        \n",
    "        # 将大输入向量映射为GRU的隐含层\n",
    "        output = self.attn_combine(output).unsqueeze(1)\n",
    "        # output大小：batch_size, length_seq, hidden_size\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # output的结果再dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # 开始解码器GRU的运算\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        \n",
    "        # output大小：batch_size, length_seq, hidden_size * directions\n",
    "        # hidden大小：n_layers * directions, batch_size, hidden_size\n",
    "        \n",
    "        #取出GRU运算最后一步的结果喂给最后一层全链接层\n",
    "        output = self.out(output[:, -1, :])\n",
    "        # output大小：batch_size * output_size\n",
    "        \n",
    "        # 取logsoftmax，计算输出结果\n",
    "        output = F.log_softmax(output)\n",
    "        # output大小：batch_size * output_size\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 初始化解码器隐单元，尺寸为n_layers * directions, batch_size, hidden_size\n",
    "        result = Variable(torch.zeros(self.n_layers * 2, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进程：0% 训练损失：95.2406，校验损失：89.4608，词正确率：41.45%\n",
      "进程：1% 训练损失：85.4721，校验损失：86.7489，词正确率：42.69%\n",
      "进程：2% 训练损失：83.9253，校验损失：85.0155，词正确率：42.91%\n",
      "进程：3% 训练损失：82.2801，校验损失：83.9268，词正确率：43.25%\n",
      "进程：4% 训练损失：80.4357，校验损失：81.9967，词正确率：43.65%\n",
      "进程：5% 训练损失：78.8866，校验损失：79.9710，词正确率：43.76%\n",
      "进程：6% 训练损失：77.0739，校验损失：78.1048，词正确率：43.99%\n",
      "进程：7% 训练损失：75.6382，校验损失：77.2445，词正确率：44.27%\n",
      "进程：8% 训练损失：74.2668，校验损失：75.9602，词正确率：44.18%\n",
      "进程：9% 训练损失：72.9534，校验损失：74.6087，词正确率：44.56%\n",
      "进程：10% 训练损失：71.6252，校验损失：73.6311，词正确率：45.06%\n",
      "进程：11% 训练损失：70.4390，校验损失：71.8183，词正确率：44.96%\n",
      "进程：12% 训练损失：69.3461，校验损失：70.2283，词正确率：45.60%\n",
      "进程：13% 训练损失：68.0799，校验损失：69.3773，词正确率：45.57%\n",
      "进程：14% 训练损失：66.9501，校验损失：68.1668，词正确率：45.94%\n",
      "进程：15% 训练损失：66.1043，校验损失：66.8379，词正确率：46.34%\n",
      "进程：16% 训练损失：64.8817，校验损失：65.1729，词正确率：46.71%\n",
      "进程：17% 训练损失：63.5005，校验损失：65.1245，词正确率：46.67%\n",
      "进程：18% 训练损失：62.7868，校验损失：63.4840，词正确率：46.99%\n",
      "进程：19% 训练损失：61.7482，校验损失：62.8754，词正确率：47.39%\n",
      "进程：20% 训练损失：60.8639，校验损失：61.3524，词正确率：47.72%\n",
      "进程：21% 训练损失：59.8074，校验损失：60.5690，词正确率：48.20%\n",
      "进程：22% 训练损失：58.8471，校验损失：59.6658，词正确率：48.48%\n",
      "进程：23% 训练损失：57.7751，校验损失：58.7953，词正确率：48.35%\n",
      "进程：24% 训练损失：56.7142，校验损失：57.6865，词正确率：48.87%\n",
      "进程：25% 训练损失：56.1366，校验损失：56.9946，词正确率：49.28%\n",
      "进程：26% 训练损失：55.2629，校验损失：56.2989，词正确率：49.77%\n",
      "进程：27% 训练损失：54.4675，校验损失：54.9929，词正确率：50.12%\n",
      "进程：28% 训练损失：53.6059，校验损失：53.8235，词正确率：50.41%\n",
      "进程：28% 训练损失：52.8570，校验损失：53.5365，词正确率：50.86%\n",
      "进程：30% 训练损失：51.9039，校验损失：52.8619，词正确率：50.98%\n",
      "进程：31% 训练损失：51.1225，校验损失：52.1100，词正确率：51.45%\n",
      "进程：32% 训练损失：50.2561，校验损失：51.2135，词正确率：52.57%\n",
      "进程：33% 训练损失：49.7676，校验损失：50.4389，词正确率：52.50%\n",
      "进程：34% 训练损失：48.9340，校验损失：49.4830，词正确率：53.01%\n",
      "进程：35% 训练损失：48.3690，校验损失：49.4394，词正确率：53.32%\n",
      "进程：36% 训练损失：47.7337，校验损失：48.2482，词正确率：53.68%\n",
      "进程：37% 训练损失：46.8642，校验损失：48.3219，词正确率：53.41%\n",
      "进程：38% 训练损失：46.3652，校验损失：46.9445，词正确率：54.51%\n",
      "进程：39% 训练损失：45.8418，校验损失：45.6949，词正确率：54.58%\n",
      "进程：40% 训练损失：45.4453，校验损失：45.7383，词正确率：54.83%\n",
      "进程：41% 训练损失：44.6598，校验损失：45.2973，词正确率：55.23%\n",
      "进程：42% 训练损失：43.9186，校验损失：44.7046，词正确率：55.82%\n",
      "进程：43% 训练损失：43.3488，校验损失：44.2075，词正确率：55.53%\n",
      "进程：44% 训练损失：43.1634，校验损失：44.2237，词正确率：55.91%\n",
      "进程：45% 训练损失：42.2350，校验损失：42.5162，词正确率：56.86%\n",
      "进程：46% 训练损失：41.9009，校验损失：41.8257，词正确率：57.02%\n",
      "进程：47% 训练损失：41.1450，校验损失：41.8566，词正确率：56.89%\n",
      "进程：48% 训练损失：40.8358，校验损失：41.5567，词正确率：57.40%\n",
      "进程：49% 训练损失：40.3803，校验损失：41.8170，词正确率：56.82%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0289c892a40b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# 反向传播开始\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m# 开始梯度下降\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf36\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gradient has to be a Tensor, Variable or None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始带有注意力机制的RNN训练\n",
    "\n",
    "#定义网络架构\n",
    "hidden_size = 256\n",
    "max_length = MAX_LENGTH\n",
    "n_layers = 1\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers = n_layers)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.5,\n",
    "                         max_length = max_length, n_layers = n_layers)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "#criterion = Batch_NLLLoss\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "# 开始训练周期循环\n",
    "plot_losses = []\n",
    "for epoch in range(num_epoch):\n",
    "    # 将解码器置于训练状态，让dropout工作\n",
    "    decoder.train()\n",
    "    print_loss_total = 0\n",
    "    # 对训练数据进行循环\n",
    "    for data in train_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "        \n",
    "        #清空梯度\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        #编码器开始工作\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 解码器开始工作\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        # 将编码器的隐含层单元取值作为编码的结果传递给解码器\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 同时按照两种方式训练解码器：用教师监督的信息作为下一时刻的输入和不用监督的信息，用自己预测结果作为下一时刻的输入\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        if use_teacher_forcing:\n",
    "            # 用监督信息作为下一时刻解码器的输入\n",
    "            # 开始时间不得循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                # 输入给解码器的信息包括输入的单词decoder_input, 解码器上一时刻的因曾单元状态，\n",
    "                # 编码器各个时间步的输出结果\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                #decoder_ouput大小：batch_size, output_size\n",
    "                #计算损失函数，得到下一时刻的解码器的输入\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "                decoder_input = target_variable[:, di].unsqueeze(1)  # Teacher forcing\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "        else:\n",
    "            # 没有教师监督，用解码器自己的预测作为下一时刻的输入\n",
    "\n",
    "            # 对时间步进行循环\n",
    "            for di in range(MAX_LENGTH):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "                # 获取解码器的预测结果，并用它来作为下一时刻的输入\n",
    "                topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "                #topi 尺寸：batch_size, k\n",
    "                ni = topi[:, 0]\n",
    "\n",
    "                decoder_input = Variable(ni.unsqueeze(1))\n",
    "                # decoder_input大小：batch_size, length_seq\n",
    "                decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                # 计算损失函数\n",
    "                loss += criterion(decoder_output, target_variable[:, di])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 反向传播开始\n",
    "        loss.backward()\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        # 开始梯度下降\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        print_loss_total += loss.data.numpy()[0]\n",
    "\n",
    "    print_loss_avg = print_loss_total / len(train_loader)\n",
    "        \n",
    "    valid_loss = 0\n",
    "    rights = []\n",
    "    # 将解码器的training设置为False，以便关闭dropout\n",
    "    decoder.eval()\n",
    "    \n",
    "    #对所有的校验数据做循环\n",
    "    for data in valid_loader:\n",
    "        input_variable = Variable(data[0]).cuda() if use_cuda else Variable(data[0])\n",
    "        # input_variable的大小：batch_size, length_seq\n",
    "        target_variable = Variable(data[1]).cuda() if use_cuda else Variable(data[1])\n",
    "        # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "        encoder_hidden = encoder.initHidden(data[0].size()[0])\n",
    "\n",
    "        loss = 0\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "        # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "        # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "        # 开始每一步的预测\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "            topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "            #topi 尺寸：batch_size, k\n",
    "            ni = topi[:, 0]\n",
    "\n",
    "            decoder_input = Variable(ni.unsqueeze(1))\n",
    "            # decoder_input大小：batch_size, length_seq\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "            rights.append(right)\n",
    "            loss += criterion(decoder_output, target_variable[:, di])\n",
    "        loss = loss.cpu() if use_cuda else loss\n",
    "        valid_loss += loss.data.numpy()[0]\n",
    "    # 计算平均损失、准确率等指标并打印输出\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('进程：%d%% 训练损失：%.4f，校验损失：%.4f，词正确率：%.2f%%' % (epoch * 1.0 / num_epoch * 100, \n",
    "                                                    print_loss_avg,\n",
    "                                                    valid_loss / len(valid_loader),\n",
    "                                                    100.0 * right_ratio))\n",
    "    plot_losses.append([print_loss_avg, valid_loss / len(valid_loader), right_ratio])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf36\\lib\\site-packages\\torch\\serialization.py:147: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tf36\\lib\\site-packages\\torch\\serialization.py:147: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x87743e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x87542a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制统计指标曲线图\n",
    "torch.save(encoder, 'encoder-final_20_h256.mdl')\n",
    "torch.save(decoder, 'decoder-final_20_h256.mdl')\n",
    "a = [i[0] for i in plot_losses]\n",
    "b = [i[1] for i in plot_losses]\n",
    "c = [i[2] * 100 for i in plot_losses]\n",
    "plt.plot(a, label = 'Training Loss')\n",
    "plt.plot(b, label = 'Validation Loss')\n",
    "plt.plot(c, label = 'Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so familiar and welcoming .\n",
      "机器翻译： 熟悉 , 的 . .\n",
      "标准翻译： 熟悉 而 亲切 .\n",
      "词准确率： 85.0\n",
      "\n",
      "\n",
      "fu quanyou also briefed the guests on china s military building .\n",
      "机器翻译： 傅全有 还 介绍 了 中国 介绍 了 中国 的 情况 情况 .\n",
      "标准翻译： 傅全有 还 向 客人 介绍 了 中国 军队 的 建设 情况 .\n",
      "词准确率： 65.0\n",
      "\n",
      "\n",
      "some us officials also have claimed that the security dialogue mechanism is for the sake of common security .\n",
      "机器翻译： 美国 认为 也 也 也 也 也 安全 的 问题 .\n",
      "标准翻译： 美国 一些 官员 也 宣称 是 为了 共同 的 安全 .\n",
      "词准确率： 65.0\n",
      "\n",
      "\n",
      "this is a very important task which we must continue to grasp firmly and well .\n",
      "机器翻译： 这是 要 重要 重要 , 必须 要 抓好 抓好 抓好 .\n",
      "标准翻译： 这项 工作 十分 重要 , 一定 要 继续 抓紧 抓好 .\n",
      "词准确率： 70.0\n",
      "\n",
      "\n",
      "the anti chemical warfare corps has also rendered many meritorious services in supporting the state s economic construction .\n",
      "机器翻译： 国家 的 国家 的 , , 防化兵 防化兵 防化兵 防化兵 防化兵 的 的 . .\n",
      "标准翻译： 在 支援 国家 经济 建设 中 , 我军 防化兵 又 屡 建 功勋 .\n",
      "词准确率： 40.0\n",
      "\n",
      "\n",
      "we welcome more uruguayan congressmen to come and visit china .\n",
      "机器翻译： 我们 欢迎 欢迎 中国 中国 中国 的 的 . .\n",
      "标准翻译： 我们 欢迎 更多 的 乌拉圭 议员 来 中国 访问 .\n",
      "词准确率： 65.0\n",
      "\n",
      "\n",
      "not long ago fifty us nobel laureates sent a joint letter to president clinton .\n",
      "机器翻译： 不久 , 军界 军界 舆论界 舆论界 了 该计划 .\n",
      "标准翻译： 美国 科学界 政界 军界 舆论界 纷纷 批评 该计划 .\n",
      "词准确率： 75.0\n",
      "\n",
      "\n",
      "why has the work of certain agencies on the network been pushed but not moved ?\n",
      "机器翻译： 为何 幺 幺 \" \" , 办公 办公 办公 推 推 推 ?\n",
      "标准翻译： 近年来 为 什 幺 有的 机关 网上 办公 一 推 就 动 ?\n",
      "词准确率： 50.0\n",
      "\n",
      "\n",
      "however the submarines of the two major fleets had set sail for exercises .\n",
      "机器翻译： 但是 , 在 两 舰队 的 潜艇 出航 出航 出航 . .\n",
      "标准翻译： 不过 两 大 舰队 的 潜艇 仍然 已 出航 演习 .\n",
      "词准确率： 50.0\n",
      "\n",
      "\n",
      "the talks centered on north korea s export of missile technology .\n",
      "机器翻译： 在 国内 的 的 的 的 的 的 的 的 .\n",
      "标准翻译： 双方 会谈 的 焦点 是 朝鲜 出口 导弹 技术 问题 .\n",
      "词准确率： 55.0\n",
      "\n",
      "\n",
      "dongshan appeared to be as quite as it was used to be .\n",
      "机器翻译： 似乎 , , 昔 昔 .\n",
      "标准翻译： 东山 似乎 平静 如 昔 .\n",
      "词准确率： 80.0\n",
      "\n",
      "\n",
      "raidi warmly welcomed the visiting group especially the taiwan journlists on their first visit to tibet .\n",
      "机器翻译： 热 总理 的 采访 , 采访 的 采访 , 台湾 采访 采访 采访 \" 台湾 的 采访 热忱 热忱 .\n",
      "标准翻译： 热 地 对 采访 团 尤其是 来自 台湾 的 记者 们 首次 前来 西藏 采访 表示 热忱 欢迎 .\n",
      "词准确率： 10.0\n",
      "\n",
      "\n",
      "the meaning is self evident .\n",
      "机器翻译： 二 是 是 的 自明 . .\n",
      "标准翻译： 其 涵义 不 言 自明 .\n",
      "词准确率： 75.0\n",
      "\n",
      "\n",
      "jiang zemin said that he was happy to meet pm morkel in cape town .\n",
      "机器翻译： 江泽民 表示 , 开普敦 开普敦 开普敦 莫克尔 莫克尔 .\n",
      "标准翻译： 江泽民 对 在 开普敦 有机会 会见 莫克尔 省长 表示 高兴 .\n",
      "词准确率： 60.0\n",
      "\n",
      "\n",
      "in his speech bashar warmly welcomed the official visit by vice president hu jintao .\n",
      "机器翻译： 巴沙尔 在 胡锦涛 对 胡锦涛 对 胡锦涛 的 的 欢迎 欢迎 .\n",
      "标准翻译： 巴沙尔 在 讲话 中 热烈 欢迎 胡锦涛 副主席 正式 访问 叙利亚 .\n",
      "词准确率： 60.0\n",
      "\n",
      "\n",
      "in shanxi s jiangxian county however the work of demonstration has turned out to be a ridiculous farce .\n",
      "机器翻译： 在 , 绛县 绛县 绛县 , , 了 了 了 荒诞 的 荒诞 荒诞 荒诞 .\n",
      "标准翻译： 但 在 山西 绛县 , 示范 工作 却 变成 了 一 场 荒诞 的 闹剧 .\n",
      "词准确率： 40.0\n",
      "\n",
      "\n",
      "however it is very important for the congress to grant china a permanent normal trade status .\n",
      "机器翻译： 但 , 中国 是 中国 建交 永久 中国 的 贸易 的 . .\n",
      "标准翻译： 但是 , 国会 给予 中国 永久 正常 贸易 地位 非常 重要 .\n",
      "词准确率： 50.0\n",
      "\n",
      "\n",
      "luo shuqing said we pin great hopes on the people in taiwan .\n",
      "机器翻译： 罗叔清 说 , \" 寄 寄 \" \" \" 的 \" .\n",
      "标准翻译： 罗叔清 说 , \" 我们 寄 大 希望 於 台湾 人民 .\n",
      "词准确率： 70.0\n",
      "\n",
      "\n",
      "this tortuous process illustrated that the issues of building socialism had not been resolved .\n",
      "机器翻译： 这 说明 说明 说明 , 的 问题 , , , 问题 的 的 的 .\n",
      "标准翻译： 这 段 曲折 历程 说明 , 怎样 建设 社会主义 的 问题 没有 解决 .\n",
      "词准确率： 35.0\n",
      "\n",
      "\n",
      "at present tibetan language newspapers and periodicals are being published .\n",
      "机器翻译： 目前 , , , , 报刊杂志 报刊杂志 报刊杂志 已达 已达 .\n",
      "标准翻译： 目前 , 正式 出版 发行 的 藏文 报刊杂志 已达 20 .\n",
      "词准确率： 70.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从测试集中随机挑选20个句子来测试翻译的结果\n",
    "indices = np.random.choice(range(len(test_X)), 20)\n",
    "for ind in indices:\n",
    "    data = [test_X[ind]]\n",
    "    target = [test_Y[ind]]\n",
    "    print(SentenceFromList(input_lang, data[0]))\n",
    "    input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "    # input_variable的大小：batch_size, length_seq\n",
    "    target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "    # target_variable的大小：batch_size, length_seq\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "    loss = 0\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    # encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "    # encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    output_sentence = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    rights = []\n",
    "    for di in range(MAX_LENGTH):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "        topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        #topi 尺寸：batch_size, k\n",
    "        ni = topi[:, 0]\n",
    "        decoder_input = Variable(ni.unsqueeze(1))\n",
    "        ni = ni[0]\n",
    "        output_sentence.append(ni)\n",
    "        # decoder_input大小：batch_size, length_seq\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "        rights.append(right)\n",
    "    sentence = SentenceFromList(output_lang, output_sentence)\n",
    "    standard = SentenceFromList(output_lang, target[0])\n",
    "    print('机器翻译：', sentence)\n",
    "    print('标准翻译：', standard)\n",
    "    # 输出本句话的准确率\n",
    "    right_ratio = 1.0 * np.sum([i[0] for i in rights]) / np.sum([i[1] for i in rights])\n",
    "    print('词准确率：', 100.0 * right_ratio)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[463, 6625, 533, 528, 670, 3140, 14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "机器翻译： 我 我 , 我 的 . .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过几个特殊的句子翻译，考察注意力机制关注的情况\n",
    "data = '人民币 汇率 继续 保持 稳定 .'\n",
    "#data = '五 是 干部 交流 工作 迈出 较大 步伐 .'\n",
    "data = '谈到 经济 合作 问题 , 两 人 找到 了 一些 共同 语言 .'\n",
    "data = 'generally speaking sino us relations have been good .'\n",
    "data = 'i love my wife very much .'\n",
    "data = [indexFromSentence(input_lang, data)]\n",
    "print(data)\n",
    "\n",
    "input_variable = Variable(torch.LongTensor(data)).cuda() if use_cuda else Variable(torch.LongTensor(data))\n",
    "# input_variable的大小：batch_size, length_seq\n",
    "target_variable = Variable(torch.LongTensor(target)).cuda() if use_cuda else Variable(torch.LongTensor(target))\n",
    "# target_variable的大小：batch_size, length_seq\n",
    "\n",
    "encoder_hidden = encoder.initHidden(input_variable.size()[0])\n",
    "\n",
    "loss = 0\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "# encoder_outputs的大小：batch_size, length_seq, hidden_size*direction\n",
    "# encoder_hidden的大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "decoder_input = Variable(torch.LongTensor([[SOS_token]] * target_variable.size()[0]))\n",
    "# decoder_input大小：batch_size, length_seq\n",
    "decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "decoder_hidden = encoder_hidden\n",
    "# decoder_hidden大小：direction*n_layer, batch_size, hidden_size\n",
    "\n",
    "output_sentence = []\n",
    "decoder_attentions = torch.zeros(max_length, max_length)\n",
    "for di in range(MAX_LENGTH):\n",
    "    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "        decoder_input, decoder_hidden, encoder_outputs)\n",
    "    #decoder_ouput大小：batch_size, output_size(vocab_size)\n",
    "    topv, topi = decoder_output.data.topk(1, dim = 1)\n",
    "    \n",
    "    # 在每一步，获取了注意力的权重向量，并将其存储到了decoder_attentions之中\n",
    "    decoder_attentions[di] = decoder_attention.data\n",
    "    #topi 尺寸：batch_size, k\n",
    "    ni = topi[:, 0]\n",
    "    decoder_input = Variable(ni.unsqueeze(1))\n",
    "    ni = ni.cpu().numpy()[0]\n",
    "    output_sentence.append(ni)\n",
    "    # decoder_input大小：batch_size, length_seq\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    right = rightness(decoder_output, target_variable[:, di].unsqueeze(1))\n",
    "    rights.append(right)\n",
    "sentence = SentenceFromList(output_lang, output_sentence)\n",
    "print('机器翻译：', sentence)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x87ba8b00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADAACAQAgUAAEAgEAIFAABD+B1RtSAgIq4hEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x876a2080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将每一步存储的注意力权重组合到一起就形成了注意力矩阵，绘制为图\n",
    "plt.matshow(decoder_attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
